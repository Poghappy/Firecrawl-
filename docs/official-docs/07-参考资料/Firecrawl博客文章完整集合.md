# Firecrawl åšå®¢æ–‡ç« å®Œæ•´é›†åˆ

> æœ¬æ–‡æ¡£åŒ…å«ä» Firecrawl å®˜æ–¹åšå®¢ (https://www.firecrawl.dev/blog/category/use-cases-and-examples) çˆ¬å–çš„æ‰€æœ‰æ–‡ç« å†…å®¹
> çˆ¬å–æ—¶é—´: 2025å¹´1æœˆ
> æ•°æ®æ¥æº: Firecrawl å®˜æ–¹åšå®¢

## ğŸ“‹ ç›®å½•

1. [How to Create a Dermatology Q&A Dataset with OpenAI Harmony & Firecrawl Search](#article-1)
2. [Building AI Applications with Kimi K2: A Complete Travel Deal Finder Tutorial](#article-2)
3. [The Best Open Source Frameworks For Building AI Agents in 2025](#article-3)
4. [How Engage Together Uses Firecrawl to Map Anti-Trafficking Resources](#article-4)
5. [Building a Medical AI Application with Grok 4](#article-5)
6. [Top 10 Tools for Web Scraping](#article-6)
7. [åšå®¢æ–‡ç« åˆ—è¡¨é¡µé¢å†…å®¹](#article-list)

---

## <a id="article-1"></a>1. How to Create a Dermatology Q&A Dataset with OpenAI Harmony & Firecrawl Search

**ä½œè€…**: Abid Ali Awan  
**å‘å¸ƒæ—¶é—´**: Aug 15, 2025  
**åŸæ–‡é“¾æ¥**: https://www.firecrawl.dev/blog/creating_dermatology_dataset_with_openai_harmony_firecrawl_search  
**åˆ†ç±»**: AI Engineering, Web Extraction

### æ‘˜è¦

æœ¬æ–‡æä¾›äº†ä¸€ä¸ªè¯¦ç»†çš„åˆ†æ­¥æŒ‡å—ï¼Œä»‹ç»å¦‚ä½•ä½¿ç”¨ Firecrawl ä»ç½‘ç»œæ”¶é›†çš®è‚¤ç§‘æ•°æ®ï¼Œä½¿ç”¨ Harmony prompt é£æ ¼å¤„ç†æ•°æ®ï¼Œä½¿ç”¨ GPT-OSS 120B ç”Ÿæˆç»“æ„åŒ–çš„é—®ç­”æ•°æ®é›†ï¼Œå¹¶å°†å…¶å‘å¸ƒåˆ° Hugging Faceï¼ŒåŒæ—¶æä¾›æ£€æŸ¥ç‚¹åŠŸèƒ½ä»¥ç¡®ä¿å¯é æ€§ã€‚

### ä¸»è¦å†…å®¹

#### ç¯å¢ƒè®¾ç½®

æ–‡ç« é¦–å…ˆä»‹ç»äº†å¦‚ä½•è®¾ç½®å¼€å‘ç¯å¢ƒï¼ŒåŒ…æ‹¬å®‰è£…å¿…è¦çš„ä¾èµ–åŒ…ï¼š

```python
# å®‰è£…å¿…è¦çš„ä¾èµ–
pip install firecrawl-py datasets huggingface_hub openai
```

#### æ•°æ®æ¨¡å‹å®šä¹‰

ä½¿ç”¨ Pydantic å®šä¹‰æ•°æ®ç»“æ„ï¼š

```python
from pydantic import BaseModel
from typing import List

class QAPair(BaseModel):
    question: str
    answer: str
    source_url: str
    confidence: float

class DermatologyDataset(BaseModel):
    qa_pairs: List[QAPair]
    metadata: dict
```

#### Web å‘ç°è¿‡ç¨‹

ä½¿ç”¨ Firecrawl çš„æœç´¢åŠŸèƒ½å‘ç°ç›¸å…³çš„çš®è‚¤ç§‘ç½‘ç«™ï¼š

```python
from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="your-api-key")

# æœç´¢çš®è‚¤ç§‘ç›¸å…³å†…å®¹
search_results = app.search(
    query="dermatology skin conditions treatment",
    limit=50
)
```

#### Prompt æ„å»º

æ–‡ç« è¯¦ç»†ä»‹ç»äº†å¦‚ä½•æ„å»ºæœ‰æ•ˆçš„ prompt æ¥æå–ç»“æ„åŒ–æ•°æ®ï¼š

```python
harmony_prompt = """
You are a medical expert specializing in dermatology. 
Analyze the following content and create question-answer pairs 
that would be useful for training a medical AI assistant.

Focus on:
- Common skin conditions
- Treatment options
- Diagnostic criteria
- Patient care guidelines

Content: {content}
"""
```

### æŠ€æœ¯äº®ç‚¹

1. **æ™ºèƒ½æ•°æ®æ”¶é›†**: ä½¿ç”¨ Firecrawl çš„æœç´¢ API è‡ªåŠ¨å‘ç°ç›¸å…³åŒ»ç–—å†…å®¹
2. **ç»“æ„åŒ–æå–**: é€šè¿‡ GPT-OSS 120B å°†éç»“æ„åŒ–å†…å®¹è½¬æ¢ä¸ºæ ‡å‡†åŒ–é—®ç­”å¯¹
3. **è´¨é‡æ§åˆ¶**: å®æ–½å¤šå±‚éªŒè¯ç¡®ä¿æ•°æ®è´¨é‡
4. **å¯é æ€§ä¿è¯**: é€šè¿‡æ£€æŸ¥ç‚¹æœºåˆ¶é˜²æ­¢æ•°æ®ä¸¢å¤±
5. **å¼€æ”¾å…±äº«**: ç›´æ¥å‘å¸ƒåˆ° Hugging Face å¹³å°ä¾›ç¤¾åŒºä½¿ç”¨

---

## <a id="article-2"></a>2. Building AI Applications with Kimi K2: A Complete Travel Deal Finder Tutorial

**ä½œè€…**: Abid Ali Awan  
**å‘å¸ƒæ—¶é—´**: Aug 5, 2025  
**åŸæ–‡é“¾æ¥**: https://www.firecrawl.dev/blog/building-ai-applications-kimi-k2-travel-deal-finder  
**åˆ†ç±»**: AI Engineering, Example Apps

### æ‘˜è¦

å­¦ä¹ å¦‚ä½•ä½¿ç”¨ Kimi K2ã€Groq Cloudã€Firecrawl API å’Œ Gradio æ„å»ºå’Œéƒ¨ç½²æ—…è¡Œä¼˜æƒ æŸ¥æ‰¾åº”ç”¨ç¨‹åºã€‚åŒ…å«å®Œæ•´çš„æ•™ç¨‹ä»£ç ç¤ºä¾‹å’Œéƒ¨ç½²æŒ‡å—ã€‚

### ä¸»è¦å†…å®¹

#### Kimi K2 ä»‹ç»

Kimi K2 æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¤§è¯­è¨€æ¨¡å‹ï¼Œç‰¹åˆ«é€‚åˆå¤„ç†å¤æ‚çš„æ¨ç†ä»»åŠ¡å’Œå¤šæ¨¡æ€å†…å®¹ã€‚æ–‡ç« ä»‹ç»äº†å…¶ä¸»è¦ç‰¹æ€§ï¼š

- è¶…é•¿ä¸Šä¸‹æ–‡çª—å£ï¼ˆ200ä¸‡+ tokensï¼‰
- å¤šè¯­è¨€æ”¯æŒ
- å¼ºå¤§çš„ä»£ç ç”Ÿæˆèƒ½åŠ›
- ä¼˜ç§€çš„æ¨ç†æ€§èƒ½

#### Groq Cloud API ä½¿ç”¨

```python
from groq import Groq

client = Groq(
    api_key="your-groq-api-key"
)

def get_travel_recommendations(destination, budget, dates):
    response = client.chat.completions.create(
        model="llama-3.1-70b-versatile",
        messages=[
            {
                "role": "system",
                "content": "You are a travel expert assistant."
            },
            {
                "role": "user",
                "content": f"Find travel deals for {destination} with budget {budget} for dates {dates}"
            }
        ]
    )
    return response.choices[0].message.content
```

#### Travel Deal Finder åº”ç”¨æ„å»º

åº”ç”¨çš„æ ¸å¿ƒåŠŸèƒ½åŒ…æ‹¬ï¼š

1. **ç›®çš„åœ°æœç´¢**: ä½¿ç”¨ Firecrawl æœç´¢æ—…è¡Œç½‘ç«™
2. **ä»·æ ¼æ¯”è¾ƒ**: ä»å¤šä¸ªæ¥æºæ”¶é›†ä»·æ ¼ä¿¡æ¯
3. **æ™ºèƒ½æ¨è**: åŸºäºç”¨æˆ·åå¥½ç”Ÿæˆä¸ªæ€§åŒ–å»ºè®®
4. **å®æ—¶æ›´æ–°**: å®šæœŸæ›´æ–°ä¼˜æƒ ä¿¡æ¯

```python
import gradio as gr
from firecrawl import FirecrawlApp

def find_travel_deals(destination, budget, travel_dates):
    # ä½¿ç”¨ Firecrawl æœç´¢æ—…è¡Œç½‘ç«™
    firecrawl = FirecrawlApp(api_key="your-key")
    
    search_query = f"travel deals {destination} {travel_dates}"
    results = firecrawl.search(query=search_query, limit=10)
    
    # å¤„ç†æœç´¢ç»“æœ
    deals = []
    for result in results:
        # æå–ä»·æ ¼å’Œè¯¦æƒ…
        deal_info = extract_deal_info(result['content'])
        deals.append(deal_info)
    
    return format_deals(deals)
```

#### Gradio UI åˆ›å»º

```python
def create_travel_app():
    with gr.Blocks(title="Travel Deal Finder") as app:
        gr.Markdown("# ğŸŒ AI Travel Deal Finder")
        
        with gr.Row():
            destination = gr.Textbox(label="Destination")
            budget = gr.Number(label="Budget ($)")
            dates = gr.Textbox(label="Travel Dates")
        
        find_btn = gr.Button("Find Deals")
        results = gr.Markdown()
        
        find_btn.click(
            find_travel_deals,
            inputs=[destination, budget, dates],
            outputs=results
        )
    
    return app

app = create_travel_app()
app.launch()
```

### æŠ€æœ¯äº®ç‚¹

1. **å¤šæ¨¡å‹é›†æˆ**: ç»“åˆ Kimi K2 å’Œ Groq Cloud çš„ä¼˜åŠ¿
2. **å®æ—¶æ•°æ®**: é€šè¿‡ Firecrawl è·å–æœ€æ–°çš„æ—…è¡Œä¿¡æ¯
3. **ç”¨æˆ·å‹å¥½ç•Œé¢**: ä½¿ç”¨ Gradio åˆ›å»ºç›´è§‚çš„ Web ç•Œé¢
4. **æ™ºèƒ½æ¨è**: åŸºäº AI çš„ä¸ªæ€§åŒ–æ—…è¡Œå»ºè®®
5. **å¯æ‰©å±•æ¶æ„**: æ˜“äºæ·»åŠ æ–°çš„æ•°æ®æºå’ŒåŠŸèƒ½

---

## <a id="article-3"></a>3. The Best Open Source Frameworks For Building AI Agents in 2025

**ä½œè€…**: Bex Tuychiev  
**å‘å¸ƒæ—¶é—´**: April 23, 2025  
**åŸæ–‡é“¾æ¥**: https://www.firecrawl.dev/blog/best-open-source-agent-frameworks-2025  
**åˆ†ç±»**: AI Engineering

### æ‘˜è¦

å‘ç° 2025 å¹´æ„å»ºå¼ºå¤§ AI ä»£ç†çš„é¡¶çº§å¼€æºæ¡†æ¶ï¼Œå…·æœ‰é«˜çº§æ¨ç†ã€å¤šä»£ç†åä½œå’Œå·¥å…·é›†æˆèƒ½åŠ›ï¼Œä»¥è½¬å˜æ‚¨çš„ä¼ä¸šå·¥ä½œæµç¨‹ã€‚

### ä¸»è¦å†…å®¹

#### AI ä»£ç†å¸‚åœºå¢é•¿

æ–‡ç« é¦–å…ˆåˆ†æäº† AI ä»£ç†å¸‚åœºçš„å¿«é€Ÿå¢é•¿ï¼š

- 2024 å¹´å¸‚åœºè§„æ¨¡è¾¾åˆ° 50 äº¿ç¾å…ƒ
- é¢„è®¡ 2030 å¹´å°†è¾¾åˆ° 280 äº¿ç¾å…ƒ
- å¹´å¤åˆå¢é•¿ç‡è¶…è¿‡ 35%

#### è¯„ä¼°æ–¹æ³•è®º

æ–‡ç« é‡‡ç”¨äº†ç³»ç»Ÿæ€§çš„è¯„ä¼°æ–¹æ³•ï¼Œè€ƒè™‘ä»¥ä¸‹å› ç´ ï¼š

1. **æ˜“ç”¨æ€§**: å­¦ä¹ æ›²çº¿å’Œå¼€å‘ä½“éªŒ
2. **åŠŸèƒ½å®Œæ•´æ€§**: æ”¯æŒçš„ AI æ¨¡å‹å’Œå·¥å…·é›†æˆ
3. **ç¤¾åŒºæ´»è·ƒåº¦**: GitHub starsã€è´¡çŒ®è€…æ•°é‡
4. **æ–‡æ¡£è´¨é‡**: æ•™ç¨‹ã€ç¤ºä¾‹å’Œ API æ–‡æ¡£
5. **ç”Ÿäº§å°±ç»ªæ€§**: ç¨³å®šæ€§å’Œå¯æ‰©å±•æ€§

#### Firecrawl FIRE-1 æ•°æ®æ”¶é›†ä»£ç†

ä½œä¸ºç‰¹è‰²ä»‹ç»ï¼Œæ–‡ç« è¯¦ç»†æè¿°äº† Firecrawl çš„ FIRE-1 ä»£ç†ï¼š

```python
from firecrawl import FirecrawlApp

# åˆå§‹åŒ– FIRE-1 ä»£ç†
app = FirecrawlApp(api_key="your-api-key")

# æ™ºèƒ½æ•°æ®æå–
result = app.extract(
    urls=["https://example.com"],
    schema={
        "type": "object",
        "properties": {
            "title": {"type": "string"},
            "content": {"type": "string"},
            "metadata": {"type": "object"}
        }
    },
    use_fire_engine=True
)
```

#### Top 6 å¼€æºæ¡†æ¶åˆ†æ

**1. LangChain**
- **ä¼˜åŠ¿**: ç”Ÿæ€ç³»ç»Ÿå®Œæ•´ï¼Œç¤¾åŒºåºå¤§
- **é€‚ç”¨åœºæ™¯**: RAG åº”ç”¨ï¼Œæ–‡æ¡£å¤„ç†
- **GitHub Stars**: 90k+

**2. CrewAI**
- **ä¼˜åŠ¿**: å¤šä»£ç†åä½œï¼Œè§’è‰²å®šä¹‰æ¸…æ™°
- **é€‚ç”¨åœºæ™¯**: å¤æ‚ä¸šåŠ¡æµç¨‹è‡ªåŠ¨åŒ–
- **GitHub Stars**: 15k+

**3. AutoGen**
- **ä¼˜åŠ¿**: å¾®è½¯æ”¯æŒï¼Œä¼ä¸šçº§åŠŸèƒ½
- **é€‚ç”¨åœºæ™¯**: å¯¹è¯å¼ AIï¼Œä»£ç ç”Ÿæˆ
- **GitHub Stars**: 25k+

**4. LangGraph**
- **ä¼˜åŠ¿**: å›¾å½¢åŒ–å·¥ä½œæµï¼ŒçŠ¶æ€ç®¡ç†
- **é€‚ç”¨åœºæ™¯**: å¤æ‚å†³ç­–æµç¨‹
- **GitHub Stars**: 8k+

**5. Swarm**
- **ä¼˜åŠ¿**: è½»é‡çº§ï¼Œæ˜“äºéƒ¨ç½²
- **é€‚ç”¨åœºæ™¯**: ç®€å•ä»£ç†ä»»åŠ¡
- **GitHub Stars**: 12k+

**6. Phidata**
- **ä¼˜åŠ¿**: æ•°æ®é©±åŠ¨ï¼Œé›†æˆå‹å¥½
- **é€‚ç”¨åœºæ™¯**: æ•°æ®åˆ†æï¼Œå•†ä¸šæ™ºèƒ½
- **GitHub Stars**: 6k+

#### ä¼ä¸šæ„å»ºä»£ç†æœ€ä½³å®è·µ

1. **æ˜ç¡®ç›®æ ‡**: å®šä¹‰æ¸…æ™°çš„ä¸šåŠ¡ç›®æ ‡å’ŒæˆåŠŸæŒ‡æ ‡
2. **é€‰æ‹©åˆé€‚æ¡†æ¶**: æ ¹æ®éœ€æ±‚é€‰æ‹©æœ€é€‚åˆçš„æ¡†æ¶
3. **æ•°æ®è´¨é‡**: ç¡®ä¿è®­ç»ƒæ•°æ®çš„è´¨é‡å’Œç›¸å…³æ€§
4. **å®‰å…¨è€ƒè™‘**: å®æ–½é€‚å½“çš„å®‰å…¨æªæ–½å’Œè®¿é—®æ§åˆ¶
5. **æŒç»­ç›‘æ§**: å»ºç«‹ç›‘æ§å’Œåé¦ˆæœºåˆ¶

### æŠ€æœ¯äº®ç‚¹

1. **å…¨é¢å¯¹æ¯”**: ç³»ç»Ÿæ€§æ¯”è¾ƒä¸»æµå¼€æºæ¡†æ¶
2. **å®ç”¨æŒ‡å¯¼**: æä¾›å…·ä½“çš„é€‰æ‹©å»ºè®®å’Œæœ€ä½³å®è·µ
3. **å‰ç»æ€§**: å…³æ³¨ 2025 å¹´çš„æŠ€æœ¯è¶‹åŠ¿
4. **ä¼ä¸šè§†è§’**: ä»ä¼ä¸šåº”ç”¨è§’åº¦åˆ†ææ¡†æ¶é€‚ç”¨æ€§

---

## <a id="article-4"></a>4. How Engage Together Uses Firecrawl to Map Anti-Trafficking Resources

**ä½œè€…**: Ashleigh Chapman  
**å‘å¸ƒæ—¶é—´**: Aug 17, 2025  
**åŸæ–‡é“¾æ¥**: https://www.firecrawl.dev/blog/how-engage-together-uses-firecrawl-to-map-anti-trafficking-resources  
**åˆ†ç±»**: Customers

### æ‘˜è¦

äº†è§£ Engage Together å¦‚ä½•åˆ©ç”¨ Firecrawl çš„ /extract API æ”¶é›†å’Œç»„ç»‡ç¤¾åŒºä¸­åäººå£è´©å–é¡¹ç›®å’Œèµ„æºçš„å…³é”®æ•°æ®ã€‚

### ä¸»è¦å†…å®¹

#### Engage Together çš„å·¥ä½œå†…å®¹

Engage Together æ˜¯ä¸€ä¸ªè‡´åŠ›äºæ‰“å‡»äººå£è´©å–çš„éè¥åˆ©ç»„ç»‡ï¼Œä»–ä»¬çš„ä¸»è¦å·¥ä½œåŒ…æ‹¬ï¼š

- **èµ„æºæ˜ å°„**: è¯†åˆ«å’Œè®°å½•åäººå£è´©å–èµ„æº
- **ç¤¾åŒºè¿æ¥**: è¿æ¥æœåŠ¡æä¾›è€…å’Œéœ€è¦å¸®åŠ©çš„äººç¾¤
- **æ•°æ®æ”¶é›†**: æ”¶é›†å’Œåˆ†æç›¸å…³æ•°æ®ä»¥æ”¹å–„æœåŠ¡
- **æ”¿ç­–å€¡å¯¼**: æ¨åŠ¨æ”¿ç­–æ”¹é©å’Œèµ„æºåˆ†é…

#### ä½¿ç”¨ Firecrawl çš„åŸå› 

ç»„ç»‡é€‰æ‹© Firecrawl çš„ä¸»è¦åŸå› ï¼š

1. **å‡†ç¡®æ€§**: èƒ½å¤Ÿå‡†ç¡®æå–å¤æ‚ç½‘ç«™çš„ç»“æ„åŒ–æ•°æ®
2. **æ•ˆç‡**: å¤§å¹…å‡å°‘æ‰‹åŠ¨æ•°æ®æ”¶é›†çš„æ—¶é—´
3. **å¯é æ€§**: ç¨³å®šçš„ API å’Œä¸€è‡´çš„æ•°æ®è´¨é‡
4. **æ˜“ç”¨æ€§**: ç®€å•çš„é›†æˆå’Œä½¿ç”¨æµç¨‹

#### å®æ–½æ¡ˆä¾‹

```python
from firecrawl import FirecrawlApp

# åˆå§‹åŒ– Firecrawl
app = FirecrawlApp(api_key="your-api-key")

# å®šä¹‰èµ„æºæ•°æ®ç»“æ„
resource_schema = {
    "type": "object",
    "properties": {
        "organization_name": {"type": "string"},
        "services_offered": {"type": "array", "items": {"type": "string"}},
        "contact_info": {
            "type": "object",
            "properties": {
                "phone": {"type": "string"},
                "email": {"type": "string"},
                "address": {"type": "string"}
            }
        },
        "target_population": {"type": "string"},
        "availability": {"type": "string"}
    }
}

# æå–åäººå£è´©å–èµ„æºä¿¡æ¯
result = app.extract(
    urls=[
        "https://example-nonprofit.org/services",
        "https://government-resources.gov/trafficking"
    ],
    schema=resource_schema
)
```

#### ä½¿ç”¨ä½“éªŒ

Ashleigh Chapman åˆ†äº«äº†ä½¿ç”¨ Firecrawl çš„ä½“éªŒï¼š

> "Firecrawl å½»åº•æ”¹å˜äº†æˆ‘ä»¬æ”¶é›†å’Œç»„ç»‡åäººå£è´©å–èµ„æºæ•°æ®çš„æ–¹å¼ã€‚ä»¥å‰éœ€è¦å‡ å‘¨æ—¶é—´æ‰‹åŠ¨æ”¶é›†çš„ä¿¡æ¯ï¼Œç°åœ¨å‡ å°æ—¶å°±èƒ½å®Œæˆã€‚æ›´é‡è¦çš„æ˜¯ï¼Œæ•°æ®çš„å‡†ç¡®æ€§å’Œä¸€è‡´æ€§å¤§å¤§æé«˜äº†ã€‚"

#### å½±å“å’Œæˆæœ

ä½¿ç”¨ Firecrawl åï¼ŒEngage Together å–å¾—äº†æ˜¾è‘—æˆæœï¼š

- **æ•ˆç‡æå‡**: æ•°æ®æ”¶é›†æ•ˆç‡æé«˜ 80%
- **è¦†ç›–èŒƒå›´æ‰©å¤§**: èƒ½å¤Ÿç›‘æ§æ›´å¤šçš„èµ„æºç½‘ç«™
- **æ•°æ®è´¨é‡æ”¹å–„**: ç»“æ„åŒ–æ•°æ®å‡å°‘äº†äººä¸ºé”™è¯¯
- **å“åº”é€Ÿåº¦**: èƒ½å¤Ÿæ›´å¿«åœ°å“åº”ç¤¾åŒºéœ€æ±‚

### æŠ€æœ¯äº®ç‚¹

1. **ç¤¾ä¼šå½±å“**: æŠ€æœ¯æœåŠ¡äºé‡è¦çš„ç¤¾ä¼šäº‹ä¸š
2. **å®ç”¨æ€§**: è§£å†³äº†å®é™…çš„ä¸šåŠ¡ç—›ç‚¹
3. **å¯æ‰©å±•æ€§**: æ”¯æŒç»„ç»‡ä¸šåŠ¡çš„å¿«é€Ÿæ‰©å±•
4. **æ•°æ®é©±åŠ¨**: å¸®åŠ©ç»„ç»‡åšå‡ºæ›´å¥½çš„å†³ç­–

---

## <a id="article-5"></a>5. Building a Medical AI Application with Grok 4

**ä½œè€…**: Abid Ali Awan  
**å‘å¸ƒæ—¶é—´**: Jul 29, 2025  
**åŸæ–‡é“¾æ¥**: https://www.firecrawl.dev/blog/building_medical_ai_application_with_grok_4  
**åˆ†ç±»**: AI Engineering, Example Apps

### æ‘˜è¦

ç»“åˆå®æ—¶æœç´¢ã€ç½‘é¡µæŠ“å–å’Œå…ˆè¿› AI çš„åŠ›é‡ï¼Œæ„å»ºä¸€ä¸ªåŒ»ç–—å¤„æ–¹åˆ†æå™¨åº”ç”¨ã€‚

### ä¸»è¦å†…å®¹

#### Grok 4 ä»‹ç»

Grok 4 æ˜¯ xAI å…¬å¸å¼€å‘çš„æœ€æ–°å¤§è¯­è¨€æ¨¡å‹ï¼Œå…·æœ‰ä»¥ä¸‹ç‰¹ç‚¹ï¼š

- **å¤šæ¨¡æ€èƒ½åŠ›**: æ”¯æŒæ–‡æœ¬å’Œå›¾åƒå¤„ç†
- **åŒ»ç–—ä¸“ä¸šæ€§**: åœ¨åŒ»ç–—é¢†åŸŸè¡¨ç°ä¼˜å¼‚
- **å®æ—¶ä¿¡æ¯**: èƒ½å¤Ÿè®¿é—®æœ€æ–°çš„åŒ»ç–—ä¿¡æ¯
- **é«˜å‡†ç¡®æ€§**: åœ¨åŒ»ç–—è¯Šæ–­ä»»åŠ¡ä¸­è¡¨ç°å‡ºè‰²

#### xAI SDK è®¾ç½®

```python
import xai
from xai import Client

# åˆå§‹åŒ– xAI å®¢æˆ·ç«¯
client = Client(
    api_key="your-xai-api-key",
    model="grok-4"
)

def analyze_prescription(prescription_text, patient_info):
    response = client.chat.completions.create(
        messages=[
            {
                "role": "system",
                "content": "You are a medical AI assistant specialized in prescription analysis."
            },
            {
                "role": "user",
                "content": f"Analyze this prescription: {prescription_text}\nPatient info: {patient_info}"
            }
        ],
        temperature=0.1  # ä½æ¸©åº¦ç¡®ä¿ä¸€è‡´æ€§
    )
    return response.choices[0].message.content
```

#### æ–‡æœ¬å’Œå›¾åƒå¤„æ–¹åˆ†æ

åº”ç”¨æ”¯æŒä¸¤ç§è¾“å…¥æ–¹å¼ï¼š

**æ–‡æœ¬å¤„æ–¹åˆ†æ**:
```python
def analyze_text_prescription(prescription_text):
    analysis = {
        "medications": extract_medications(prescription_text),
        "dosages": extract_dosages(prescription_text),
        "interactions": check_drug_interactions(prescription_text),
        "warnings": identify_warnings(prescription_text)
    }
    return analysis
```

**å›¾åƒå¤„æ–¹åˆ†æ**:
```python
import base64
from PIL import Image

def analyze_image_prescription(image_path):
    # è¯»å–å’Œç¼–ç å›¾åƒ
    with open(image_path, "rb") as image_file:
        image_data = base64.b64encode(image_file.read()).decode()
    
    response = client.chat.completions.create(
        messages=[
            {
                "role": "user",
                "content": [
                    {
                        "type": "text",
                        "text": "Analyze this prescription image and extract all relevant information."
                    },
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_data}"
                        }
                    }
                ]
            }
        ]
    )
    return response.choices[0].message.content
```

#### Firecrawl é›†æˆæ„å»ºåŒ»ç–—å¤„æ–¹åˆ†æå™¨

```python
from firecrawl import FirecrawlApp
import json

class MedicalPrescriptionAnalyzer:
    def __init__(self, xai_api_key, firecrawl_api_key):
        self.xai_client = Client(api_key=xai_api_key)
        self.firecrawl = FirecrawlApp(api_key=firecrawl_api_key)
    
    def get_drug_information(self, drug_name):
        """ä½¿ç”¨ Firecrawl æœç´¢è¯ç‰©ä¿¡æ¯"""
        search_results = self.firecrawl.search(
            query=f"{drug_name} medication information side effects",
            limit=5
        )
        
        drug_info = []
        for result in search_results:
            info = self.extract_drug_info(result['content'])
            drug_info.append(info)
        
        return drug_info
    
    def analyze_prescription_comprehensive(self, prescription):
        """ç»¼åˆåˆ†æå¤„æ–¹"""
        # åŸºç¡€åˆ†æ
        basic_analysis = self.analyze_text_prescription(prescription)
        
        # è·å–æ¯ç§è¯ç‰©çš„è¯¦ç»†ä¿¡æ¯
        detailed_info = {}
        for medication in basic_analysis['medications']:
            detailed_info[medication] = self.get_drug_information(medication)
        
        # ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        report = {
            "basic_analysis": basic_analysis,
            "detailed_drug_info": detailed_info,
            "safety_assessment": self.assess_safety(basic_analysis, detailed_info),
            "recommendations": self.generate_recommendations(basic_analysis, detailed_info)
        }
        
        return report
```

#### ç”¨æˆ·ç•Œé¢

```python
import streamlit as st

def create_medical_app():
    st.title("ğŸ¥ Medical Prescription Analyzer")
    
    # è¾“å…¥é€‰é¡¹
    input_type = st.radio("Choose input type:", ["Text", "Image"])
    
    if input_type == "Text":
        prescription_text = st.text_area("Enter prescription text:")
        if st.button("Analyze Prescription"):
            if prescription_text:
                analyzer = MedicalPrescriptionAnalyzer(
                    xai_api_key=st.secrets["XAI_API_KEY"],
                    firecrawl_api_key=st.secrets["FIRECRAWL_API_KEY"]
                )
                result = analyzer.analyze_prescription_comprehensive(prescription_text)
                st.json(result)
    
    elif input_type == "Image":
        uploaded_file = st.file_uploader("Upload prescription image", type=["jpg", "jpeg", "png"])
        if uploaded_file and st.button("Analyze Image"):
            # å¤„ç†å›¾åƒä¸Šä¼ å’Œåˆ†æ
            pass

if __name__ == "__main__":
    create_medical_app()
```

### æŠ€æœ¯äº®ç‚¹

1. **å¤šæ¨¡æ€å¤„ç†**: æ”¯æŒæ–‡æœ¬å’Œå›¾åƒè¾“å…¥
2. **å®æ—¶ä¿¡æ¯**: é€šè¿‡ Firecrawl è·å–æœ€æ–°è¯ç‰©ä¿¡æ¯
3. **ç»¼åˆåˆ†æ**: ç»“åˆå¤šä¸ªæ•°æ®æºè¿›è¡Œå…¨é¢åˆ†æ
4. **å®‰å…¨æ€§**: é‡ç‚¹å…³æ³¨è¯ç‰©å®‰å…¨å’Œç›¸äº’ä½œç”¨
5. **ç”¨æˆ·å‹å¥½**: ç›´è§‚çš„ Streamlit ç•Œé¢

---

## <a id="article-6"></a>6. Top 10 Tools for Web Scraping

**ä½œè€…**: Abid Ali Awan  
**å‘å¸ƒæ—¶é—´**: Jul 23, 2025  
**åŸæ–‡é“¾æ¥**: https://www.firecrawl.dev/blog/top_10_tools_for_web_scraping  
**åˆ†ç±»**: Web Extraction

### æ‘˜è¦

æ¢ç´¢æœ€ä½³çš„ AIã€æ— ä»£ç ã€Python å’Œæµè§ˆå™¨è‡ªåŠ¨åŒ–ç½‘é¡µæŠ“å–å·¥å…·ã€‚

### ä¸»è¦å†…å®¹

è‡ªä»åŠ å…¥ Firecrawl ä»¥æ¥ï¼Œæˆ‘æ„è¯†åˆ°ç½‘é¡µæŠ“å–å˜å¾—å¤šä¹ˆå®¹æ˜“ï¼Œç‰¹åˆ«æ˜¯åœ¨ AI å·¥å…·çš„å¸®åŠ©ä¸‹ã€‚ä¸æ‰‹åŠ¨å®Œæˆæ‰€æœ‰å·¥ä½œç›¸æ¯”ï¼Œè¿™ä¸ªè¿‡ç¨‹è¦ç®€å•å¾—å¤šã€‚æ¯ä¸ªç½‘ç«™éƒ½æœ‰è‡ªå·±çš„å¸ƒå±€ã€ç‹¬ç‰¹çš„è¦æ±‚å’Œç‰¹å®šçš„é™åˆ¶ã€‚æƒ³è±¡ä¸€ä¸‹å¿…é¡»ä¸ºæ¯ä¸ªé¡µé¢ç¼–å†™å’Œç»´æŠ¤è‡ªå®šä¹‰ä»£ç ï¼Œè¿™å¯èƒ½æ˜¯ç›¸å½“åŠ³åŠ¨å¯†é›†å‹çš„ã€‚

è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘æ•´ç†äº†è¿™ä¸ªè·¨å‡ ä¸ªç±»åˆ«çš„**é¡¶çº§ç½‘é¡µæŠ“å–å·¥å…·**åˆ—è¡¨ï¼š**AI é©±åŠ¨çš„å·¥å…·ã€æ— ä»£ç æˆ–ä½ä»£ç å¹³å°ã€Python åº“å’Œæµè§ˆå™¨è‡ªåŠ¨åŒ–è§£å†³æ–¹æ¡ˆ**ã€‚æ¯ä¸ªå·¥å…·éƒ½æœ‰è‡ªå·±çš„ä¼˜ç¼ºç‚¹ï¼Œæ‚¨çš„é€‰æ‹©æœ€ç»ˆå°†å–å†³äºä¸¤ä¸ªä¸»è¦å› ç´ ï¼šæ‚¨çš„æŠ€æœ¯èƒŒæ™¯å’Œæ‚¨çš„é¢„ç®—ã€‚

#### AI ç½‘é¡µæŠ“å–å·¥å…·

AI ç½‘é¡µæŠ“å–å·¥å…·ä½¿ç”¨æœºå™¨å­¦ä¹ å’Œå¤§è¯­è¨€æ¨¡å‹ (LLM) æ™ºèƒ½åœ°ä»å¤æ‚çš„ã€JavaScript é‡åº¦æˆ–å—ä¿æŠ¤çš„ç½‘ç«™ä¸­æå–æ•°æ®ï¼Œä½¿ç”¨æˆ·èƒ½å¤Ÿä»¥æ¯”ä¼ ç»Ÿæ–¹æ³•æ›´é«˜çš„å‡†ç¡®æ€§å’Œæ•ˆç‡ç²¾ç¡®å®šä½å’Œæ£€ç´¢æ‰€éœ€çš„ä¿¡æ¯ã€‚

**1. Firecrawl**

[Firecrawl](https://www.firecrawl.dev/) æ˜¯ä¸€ä¸ªé’ˆå¯¹é€Ÿåº¦å’Œæ•ˆç‡ä¼˜åŒ–çš„ AI é©±åŠ¨ç½‘é¡µæŠ“å–å·¥å…·ï¼Œéå¸¸é€‚åˆå¤§è§„æ¨¡æ•°æ®æå–é¡¹ç›®ã€‚å®ƒè®©æ‚¨å°†ä»»ä½•ç½‘ç«™è½¬æ¢ä¸ºå¹²å‡€çš„ã€LLM å°±ç»ªçš„ markdown æˆ–ç»“æ„åŒ–æ•°æ®ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**

1. **Scrape**: ä»¥ markdownã€ç»“æ„åŒ–æ•°æ®ã€æˆªå›¾æˆ– HTML æ ¼å¼ä»å•ä¸ª URL æå–å†…å®¹
2. **Crawl**: ä»ç½‘é¡µä¸Šçš„æ‰€æœ‰ URL æ”¶é›†å†…å®¹ï¼Œä¸ºæ¯ä¸ªè¿”å› LLM å°±ç»ªçš„ markdown
3. **Map**: å¿«é€Ÿæ£€ç´¢ç½‘ç«™çš„æ‰€æœ‰ URL
4. **Search**: æœç´¢ç½‘ç»œå¹¶æä¾›ç»“æœçš„å®Œæ•´å†…å®¹
5. **Extract**: ä½¿ç”¨ AI ä»å•ä¸ªé¡µé¢ã€å¤šä¸ªé¡µé¢æˆ–æ•´ä¸ªç½‘ç«™è·å–ç»“æ„åŒ–æ•°æ®
6. **LLMs.txt**: ä¸º LLM è®­ç»ƒç”Ÿæˆ llms.txt æ–‡ä»¶

**ä¼˜ç‚¹ï¼š**
- æå¿«çš„æ•°æ®æ£€ç´¢ï¼Œèƒ½å¤Ÿé«˜æ•ˆçˆ¬å–æ•°ç™¾ä¸‡é¡µé¢
- å¤„ç†å¤æ‚ç½‘ç«™ï¼ŒåŒ…æ‹¬å…·æœ‰åŠ¨æ€ JavaScript å†…å®¹ã€åæœºå™¨äººæœºåˆ¶å’Œåª’ä½“æ–‡ä»¶ï¼ˆå¦‚ PDF å’Œå›¾åƒï¼‰çš„ç½‘ç«™
- é«˜åº¦å¯å®šåˆ¶ï¼Œå…·æœ‰çˆ¬å–æ·±åº¦ã€æ ‡ç­¾æ’é™¤ã€èº«ä»½éªŒè¯å’Œé¢„æå–æ“ä½œç­‰é€‰é¡¹

**ç¼ºç‚¹ï¼š**
- é«˜çº§åŠŸèƒ½å’Œè‡ªå®šä¹‰å¯èƒ½æœ‰å­¦ä¹ æ›²çº¿ï¼Œç‰¹åˆ«æ˜¯å¯¹äºéæŠ€æœ¯ç”¨æˆ·
- åƒæ‰€æœ‰çˆ¬è™«ä¸€æ ·ï¼Œå¯èƒ½ä¼šé‡åˆ°æŸäº›ç½‘ç«™çš„æ³•å¾‹æˆ–é“å¾·é™åˆ¶
- LLM é©±åŠ¨çš„ç½‘é¡µæŠ“å–ä»å¤„äºæµ‹è¯•é˜¶æ®µï¼Œå¯èƒ½å­˜åœ¨é—®é¢˜

**å®šä»·ï¼š**
- Free: $0/æœˆ
- Hobby: $16/æœˆ
- Standard: $83/æœˆ
- Growth: $333/æœˆ
- Enterprise: è‡ªå®šä¹‰å®šä»·

**ç¤ºä¾‹ä»£ç ï¼š**

```python
from firecrawl import FirecrawlApp

app = FirecrawlApp(api_key="fc-YOUR_API_KEY")

# æŠ“å–ç½‘ç«™ï¼š
scrape_result = app.scrape_url('https://abid.work/', formats=['markdown', 'html'])
print(scrape_result)
```

**2. ScrapeGraphAI**

[ScrapeGraphAI](https://scrapegraphai.com/) æ˜¯ä¸€ä¸ª AI é©±åŠ¨çš„ç½‘é¡µæ•°æ®æå–å·¥å…·ï¼Œæ“…é•¿ç†è§£å¤æ‚çš„ç½‘é¡µç»“æ„ï¼Œå®ç°é«˜åº¦å‡†ç¡®çš„æ•°æ®æå–ã€‚å®ƒæ—¢å¯ä½œä¸ºå¼€æºåº“ï¼Œä¹Ÿå¯ä½œä¸ºé«˜çº§ API ä½¿ç”¨ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**

1. **SmartScraper**: é’ˆå¯¹ä»»ä½•ç½‘é¡µçš„ AI é©±åŠ¨æå–ï¼Œåªéœ€è¦ç”¨æˆ·æç¤ºå’Œè¾“å…¥æº
2. **SearchScraper**: LLM é©±åŠ¨çš„ç½‘ç»œæœç´¢æœåŠ¡
3. **SmartCrawler**: çˆ¬å–å¹¶ä»å¤šä¸ªé¡µé¢æå–æ•°æ®
4. **Markdownify**: å°†ç½‘ç«™å†…å®¹è½¬æ¢ä¸º Markdown æ ¼å¼

**ä¼˜ç‚¹ï¼š**
- AI é©±åŠ¨çš„æå–å‡å°‘äº†æ‰‹åŠ¨ HTML åˆ†æçš„éœ€è¦
- æå…¶çµæ´»å’Œé€‚åº”æ€§å¼ºï¼Œå¤„ç†å„ç§ç½‘ç»œç»“æ„å’Œå†…å®¹ç±»å‹
- å¼€æºï¼Œé‡‡ç”¨ MIT è®¸å¯è¯

**ç¼ºç‚¹ï¼š**
- æ€§èƒ½å’Œå‡†ç¡®æ€§å¯èƒ½å› ç›®æ ‡ç½‘ç«™çš„å¤æ‚æ€§å’Œ AI æç¤ºçš„è´¨é‡è€Œå¼‚
- æ”¯æŒå’ŒåŠŸèƒ½é›†å¯èƒ½ä¸å¦‚ä¸€äº›å¤§å‹å•†ä¸šç«äº‰å¯¹æ‰‹å¹¿æ³›
- ç»“æœæœ‰æ—¶å¯èƒ½éœ€è¦æ‰‹åŠ¨éªŒè¯æˆ–åå¤„ç†

**å®šä»·ï¼š**
- Free: $0/æœˆ
- Starter: $17/æœˆ
- Growth: $85/æœˆ
- Pro: $425/æœˆ
- Enterprise: è‡ªå®šä¹‰å®šä»·

**ç¤ºä¾‹ä»£ç ï¼š**

```python
from scrapegraph_py import Client
from scrapegraph_py.logger import sgai_logger

sgai_logger.set_logging(level="INFO")

# åˆå§‹åŒ–å®¢æˆ·ç«¯
sgai_client = Client(api_key="your-sgai-api-key")
# SmartScraper è¯·æ±‚
response = sgai_client.smartscraper(
    website_url="https://abid.work/",
    user_prompt="Extract the AI blogs' links"
)

# æ‰“å°å“åº”
print(f"Request ID: {response['request_id']}")
print(f"Result: {response['result']}")
if response.get('reference_urls'):
    print(f"Reference URLs: {response['reference_urls']}")

sgai_client.close()
```

**3. Crawl4AI**

[Crawl4AI](https://github.com/unclecode/crawl4ai) æ˜¯ä¸€ä¸ªé’ˆå¯¹åŸºäº LLM çš„ç½‘é¡µæŠ“å–ä»£ç†ä¼˜åŒ–çš„å¼€æº Python åº“ã€‚å®ƒåˆ©ç”¨å¤§è¯­è¨€æ¨¡å‹ä»é™æ€å’ŒåŠ¨æ€ç½‘ç«™ï¼ˆåŒ…æ‹¬å…·æœ‰å¤æ‚ JavaScript æ¸²æŸ“çš„ç½‘ç«™ï¼‰ä¸­æå–ç»“æ„åŒ–æ•°æ®ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**

1. **è‡ªé€‚åº”çˆ¬å–**: å­¦ä¹ ç½‘ç«™æ¨¡å¼å¹¶çŸ¥é“ä½•æ—¶åœæ­¢ï¼Œä¼˜åŒ–çˆ¬å–æ•ˆç‡
2. **ç»“æ„åŒ–æ•°æ®æå–**: æ”¯æŒ LLM é©±åŠ¨ã€CSS/XPath å’ŒåŸºäºæ¨¡å¼çš„æå–ä»¥è·å¾—ç»“æ„åŒ–è¾“å‡º
3. **Markdown ç”Ÿæˆ**: ç”Ÿæˆé’ˆå¯¹ LLM å’Œ RAG ç®¡é“ä¼˜åŒ–çš„å¹²å‡€ã€ç®€æ´çš„ Markdown
4. **çµæ´»çš„æµè§ˆå™¨æ§åˆ¶**: æä¾›ä¼šè¯ç®¡ç†ã€ä»£ç†æ”¯æŒã€éšèº«æ¨¡å¼å’Œå¤šæµè§ˆå™¨å…¼å®¹æ€§
5. **åª’ä½“å’Œå…ƒæ•°æ®æå–**: æ•è·å›¾åƒã€è§†é¢‘ã€è¡¨æ ¼å’Œå…ƒæ•°æ®ï¼ŒåŒ…æ‹¬ PDF å¤„ç†

**ä¼˜ç‚¹ï¼š**
- å®Œå…¨å¼€æºï¼Œæ—  API å¯†é’¥æˆ–ä»˜è´¹å¢™ï¼Œç¡®ä¿å¯è®¿é—®æ€§å’Œé€æ˜åº¦
- å¿«é€Ÿçˆ¬å–å’Œé«˜æ•ˆçš„èµ„æºç®¡ç†
- é€šè¿‡ pip æˆ– Docker è½»æ¾éƒ¨ç½²ï¼Œå…·æœ‰äº‘é›†æˆå’Œå¯æ‰©å±•æ¶æ„

**ç¼ºç‚¹ï¼š**
- é«˜çº§åŠŸèƒ½å’Œé…ç½®é€‰é¡¹å¯èƒ½å¯¹åˆå­¦è€…æœ‰å­¦ä¹ æ›²çº¿
- æ€§èƒ½å’Œæå–è´¨é‡å¯èƒ½å› ç½‘ç«™å¤æ‚æ€§å’Œåæœºå™¨äººæªæ–½è€Œå¼‚
- ä½œä¸ºå¼€æºé¡¹ç›®ï¼ŒæŸäº›åŠŸèƒ½å¯èƒ½æ˜¯å®éªŒæ€§çš„æˆ–å¯èƒ½å‘ç”Ÿå˜åŒ–

**å®šä»·**: å…è´¹å’Œå¼€æºï¼ˆç”¨æˆ·å¯èƒ½ä¸º LLM API è°ƒç”¨å’ŒåŸºç¡€è®¾æ–½ä»˜è´¹ï¼‰ã€‚

**ç¤ºä¾‹ä»£ç ï¼š**

```python
import asyncio
from crawl4ai import *

async def main():
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(
            url="https://abid.work/",
        )
        print(result.markdown)

if __name__ == "__main__":
    asyncio.run(main())
```

#### æ— ä»£ç æˆ–ä½ä»£ç ç½‘é¡µæŠ“å–å·¥å…·

æ— ä»£ç æˆ–ä½ä»£ç ç½‘é¡µæŠ“å–å·¥å…·ä¸“ä¸ºéæŠ€æœ¯ç”¨æˆ·è®¾è®¡ï¼Œå…è®¸ä»»ä½•äººä½¿ç”¨ç›´è§‚çš„ç‚¹å‡»ç•Œé¢ã€é¢„æ„å»ºæ¨¡æ¿å’Œ AI é©±åŠ¨çš„è‡ªåŠ¨åŒ–æ¥æå–ç½‘ç«™æ•°æ®ã€‚

**4. Octoparse**

[Octoparse](https://www.octoparse.com/) æ˜¯ä¸€ä¸ªå…·æœ‰æ‹–æ”¾ç•Œé¢çš„æ— ä»£ç ç½‘é¡µæŠ“å–å¹³å°ï¼Œä½¿æ•°æ®æå–å¯¹æ¯ä¸ªäººéƒ½å¯è®¿é—®ï¼Œæ— è®ºæŠ€æœ¯èƒŒæ™¯å¦‚ä½•ã€‚å®ƒæä¾›é¢„æ„å»ºæ¨¡æ¿ã€äº‘æå–å’ŒåŒ¿åæŠ“å–åŠŸèƒ½ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**

1. **æ— ä»£ç å·¥ä½œæµè®¾è®¡å™¨**: åœ¨åŸºäºæµè§ˆå™¨çš„ç•Œé¢ä¸­æ„å»ºå’Œå¯è§†åŒ–æŠ“å–ä»»åŠ¡
2. **AI é©±åŠ¨åŠ©æ‰‹**: è‡ªåŠ¨æ£€æµ‹æ•°æ®å­—æ®µå¹¶æä¾›å®æ—¶æç¤ºä»¥ç®€åŒ–è®¾ç½®
3. **åŸºäºäº‘çš„è‡ªåŠ¨åŒ–**: å®‰æ’æŠ“å–å™¨åœ¨äº‘ä¸­ 24/7 è¿è¡Œï¼Œå…·æœ‰è‡ªåŠ¨æ•°æ®å¯¼å‡ºå’Œ OpenAPI æ”¯æŒ
4. **é«˜çº§äº¤äº’**: æ”¯æŒ IP è½®æ¢ã€éªŒè¯ç è§£å†³ã€ä»£ç†ã€æ— é™æ»šåŠ¨ã€AJAXã€ä¸‹æ‹‰èœå•ç­‰
5. **æ¨¡æ¿åº“**: æ•°ç™¾ä¸ªé’ˆå¯¹ Twitterã€Google Mapsã€LinkedInã€Amazon ç­‰çƒ­é—¨ç½‘ç«™çš„ç°æˆæ¨¡æ¿
6. **çµæ´»å¯¼å‡º**: ä»¥å¤šç§æ ¼å¼å¯¼å‡ºæ•°æ®å¹¶é€šè¿‡ API ä¸å…¶ä»–å·¥å…·é›†æˆ

**ä¼˜ç‚¹ï¼š**
- æ— ä»£ç ç”¨æˆ·å‹å¥½ç•Œé¢ï¼Œéå¸¸é€‚åˆåˆå­¦è€…å’ŒéæŠ€æœ¯ç”¨æˆ·
- é€šè¿‡ AI è‡ªåŠ¨æ£€æµ‹å’Œå¤§å‹é¢„æ„å»ºæ¨¡æ¿åº“å¿«é€Ÿè®¾ç½®
- åŸºäºäº‘çš„è‡ªåŠ¨åŒ–å®ç°å…æ‰‹åŠ¨ã€å®šæ—¶æŠ“å–

**ç¼ºç‚¹ï¼š**
- ä¸åŸºäºä»£ç æˆ–å¼€æºå·¥å…·ç›¸æ¯”ï¼Œé«˜çº§è‡ªå®šä¹‰å—é™
- å¤„ç†å¤§è§„æ¨¡æŠ“å–ä»»åŠ¡æ—¶æ€§èƒ½è¾ƒæ…¢
- å…è´¹è®¡åˆ’æœ‰æ˜¾è‘—é™åˆ¶

**å®šä»·ï¼š**
- Free: $0/æœˆ
- Standard: $99/æœˆ
- Professional: $249/æœˆ
- Enterprise: è‡ªå®šä¹‰å®šä»·

**5. Browse.AI**

[Browse.AI](https://www.browse.ai/) æ˜¯ä¸€ä¸ªæ— ä»£ç å·¥å…·ï¼Œè®©ç”¨æˆ·åˆ›å»º"æœºå™¨äºº"æ¥æ¨¡æ‹Ÿäººç±»æµè§ˆå¹¶æå–æ•°æ®ã€‚å®ƒä¸“ä¸ºå¯»æ±‚åœ¨æ²¡æœ‰æŠ€æœ¯ä¸“ä¸šçŸ¥è¯†çš„æƒ…å†µä¸‹è‡ªåŠ¨åŒ–æ•°æ®æ”¶é›†çš„å•†ä¸šç”¨æˆ·è€Œè®¾è®¡ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**

1. **æ— ä»£ç ç‚¹å‡»è®¾ç½®**: åœ¨å‡ åˆ†é’Ÿå†…ä»ä»»ä½•ç½‘ç«™æå–æ•°æ®ï¼Œæ— éœ€ç¼–å†™ä»£ç 
2. **AI é©±åŠ¨ç›‘æ§**: é€šè¿‡ç½‘ç«™å¸ƒå±€ç›‘æ§å’Œç±»äººè¡Œä¸ºæ¨¡æ‹Ÿè‡ªåŠ¨ä¿æŒæ•°æ®æœ€æ–°
3. **æ·±åº¦æŠ“å–**: ä½¿ç”¨è¿æ¥çš„æœºå™¨äººè‡ªåŠ¨ä»é¡µé¢å’Œå­é¡µé¢æå–
4. **é¢„æ„å»ºæœºå™¨äºº**: 200+ é’ˆå¯¹çƒ­é—¨ç½‘ç«™å’Œç”¨ä¾‹çš„ç°æˆæœºå™¨äººï¼Œæˆ–ä¸ºä»»ä½•ç½‘ç«™åˆ›å»ºè‡ªå®šä¹‰æœºå™¨äºº
5. **åŸºäºäº‘çš„è‡ªåŠ¨åŒ–**: å®‰æ’ä»»åŠ¡åœ¨ç‰¹å®šé—´éš”è¿è¡Œå¹¶æ¥æ”¶æ•°æ®å˜åŒ–çš„å®æ—¶è­¦æŠ¥
6. **å¼ºå¤§çš„åæœºå™¨äººåŠŸèƒ½**: å†…ç½®æœºå™¨äººæ£€æµ‹ã€ä»£ç†ç®¡ç†ã€éªŒè¯ç è§£å†³å’Œé€Ÿç‡é™åˆ¶
7. **æ— ç¼é›†æˆ**: å°†æå–çš„æ•°æ®è¿æ¥åˆ° Google Sheetsã€Airtableã€Zapierã€APIã€webhooks å’Œ 7,000+ å…¶ä»–åº”ç”¨

**ä¼˜ç‚¹ï¼š**
- é€šè¿‡ç›´è§‚çš„ç‚¹å‡»ç•Œé¢å’Œé¢„æ„å»ºæœºå™¨äººå¿«é€Ÿè®¾ç½®
- å¯æ‰©å±•ï¼Œé€‚ç”¨äºå°å‹å’Œä¼ä¸šçº§æ•°æ®æå–éœ€æ±‚
- é€šè¿‡ AI é©±åŠ¨ç›‘æ§å’Œè‡ªåŠ¨é‡è¯•å®ç°å¯é çš„æ•°æ®æå–

**ç¼ºç‚¹ï¼š**
- ä¸€äº›ä»˜è´¹é€‰é¡¹æœ‰é™ï¼Œæ›´é«˜çš„è®¢é˜…å¯èƒ½å˜å¾—æ˜‚è´µ
- å¯èƒ½é¢ä¸´é«˜åº¦åŠ¨æ€æˆ–ç™»å½•ä¿æŠ¤ç½‘ç«™çš„æŒ‘æˆ˜
- æå–é€Ÿåº¦å’Œå¯é æ€§å¯èƒ½å› ç½‘ç«™å¤æ‚æ€§å’Œåæœºå™¨äººæªæ–½è€Œå¼‚

**å®šä»·ï¼š**
- Free: $0/æœˆ
- Personal: $19/æœˆ
- Professional: $69/æœˆ
- Premium: $500/æœˆ

#### Python ç½‘é¡µæŠ“å–å·¥å…·

Python ç½‘é¡µæŠ“å–å·¥å…·ç®€åŒ–äº†ä»ç½‘ç«™æ”¶é›†ã€è§£æå’Œè‡ªåŠ¨åŒ–æ•°æ®æå–ã€‚å®ƒä»¬å¯ä»¥å¤„ç†ä»é™æ€ HTML åˆ°åŠ¨æ€ JavaScript é©±åŠ¨å†…å®¹çš„æ‰€æœ‰å†…å®¹ï¼Œä½†éœ€è¦æŠ€æœ¯ä¸“ä¸šçŸ¥è¯†ã€‚

**6. Beautiful Soup**

[Beautiful Soup](https://www.crummy.com/software/BeautifulSoup/) æ˜¯ä¸€ä¸ªç”¨äºè§£æ HTML å’Œ XML æ–‡æ¡£çš„æµè¡Œ Python åº“ï¼Œä½¿å…¶æˆä¸ºç½‘é¡µæŠ“å–ä»»åŠ¡çš„é¦–é€‰å·¥å…·ã€‚å®ƒé€šå¸¸ä¸ `requests` åº“ä¸€èµ·ä½¿ç”¨ã€‚å…¶ç®€å•ç›´è§‚çš„ API ä½¿å…¶å¯¹åˆå­¦è€…å‹å¥½ï¼Œéå¸¸é€‚åˆå°åˆ°ä¸­ç­‰è§„æ¨¡çš„ç½‘é¡µæŠ“å–é¡¹ç›®ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**

1. **å‡†ç¡®è§£æ**: è§£æå’Œå¯¼èˆª HTML å’Œ XML æ–‡æ¡£ä»¥æå–æ•°æ®
2. **çµæ´»æœç´¢**: æ”¯æŒæŒ‰æ ‡ç­¾ã€ç±»ã€idã€å±æ€§å’Œæ–‡æœ¬å†…å®¹æœç´¢å…ƒç´ 
3. **æ ‘å¯¼èˆª**: å…è®¸éå†æ–‡æ¡£æ ‘ä»¥æŸ¥æ‰¾çˆ¶ã€å…„å¼Ÿå’Œå­å…ƒç´ 
4. **æ•°æ®ä¿®æ”¹**: èƒ½å¤Ÿä¿®æ”¹è§£æçš„æ–‡æ¡£ï¼Œå¦‚ç¼–è¾‘æˆ–åˆ é™¤å…ƒç´ 
5. **å¤šè§£æå™¨æ”¯æŒ**: ä¸ä¸åŒçš„è§£æå™¨å…¼å®¹ï¼Œå¦‚ `lxml` å’Œ `html.parser`ï¼Œä»¥è·å¾—é€Ÿåº¦å’Œçµæ´»æ€§

**ä¼˜ç‚¹ï¼š**
- éå¸¸é€‚åˆå°åˆ°ä¸­ç­‰è§„æ¨¡çš„é¡¹ç›®å’Œå¿«é€ŸåŸå‹åˆ¶ä½œ
- çµæ´»ä¸”å¼ºå¤§ï¼Œç”¨äºè§£æå’Œä» HTML/XML æå–æ•°æ®
- å¾ˆå¥½åœ°å¤„ç†æ ¼å¼ä¸è‰¯çš„ HTML

**ç¼ºç‚¹ï¼š**
- ç¼ºä¹å¤„ç† JavaScript æ¸²æŸ“å†…å®¹çš„å†…ç½®æ”¯æŒ
- åœ¨è§£æéå¸¸å¤§çš„æ–‡æ¡£æ—¶å¯èƒ½æ¯”æŸäº›æ›¿ä»£æ–¹æ¡ˆæ…¢
- éœ€è¦æ‰‹åŠ¨å¤„ç†åæœºå™¨äººæªæ–½å’Œé€Ÿç‡é™åˆ¶

**å®šä»·**: å…è´¹å’Œå¼€æºã€‚

**ç¤ºä¾‹ä»£ç ï¼š**

```python
import requests
from bs4 import BeautifulSoup

url = "https://abid.work/"
response = requests.get(url)
html_content = response.content

soup = BeautifulSoup(html_content, "html.parser")
page_title = soup.title.string
print("Page Title:", page_title)
```

**7. Scrapy**

[Scrapy](https://github.com/scrapy/scrapy) æ˜¯ä¸€ä¸ªå¼ºå¤§çš„å¼€æº Python æ¡†æ¶ï¼Œä¸“ä¸ºå¤§è§„æ¨¡ç½‘é¡µæŠ“å–å’Œçˆ¬å–è€Œè®¾è®¡ã€‚å®ƒä½¿å¼€å‘äººå‘˜èƒ½å¤Ÿæ„å»ºè‡ªå®šä¹‰èœ˜è››ï¼Œé«˜æ•ˆåœ°ä»ç½‘ç«™æå–æ•°æ®ï¼Œåˆ©ç”¨å¼‚æ­¥è¯·æ±‚å’Œå¼ºå¤§çš„æ¶æ„å®ç°å¯æ‰©å±•æ€§ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**

1. **å¼‚æ­¥è¯·æ±‚**: å¹¶å‘å¤„ç†å¤šä¸ªè¯·æ±‚ä»¥å®ç°é«˜é€ŸæŠ“å–
2. **è‡ªå®šä¹‰èœ˜è››**: å®šä¹‰ç§°ä¸º"èœ˜è››"çš„ Python ç±»ä»¥çµæ´»åœ°çˆ¬å–é¡µé¢å’Œæå–æ•°æ®
3. **å†…ç½®æ•°æ®ç®¡é“**: ä»¥å„ç§æ ¼å¼ï¼ˆJSONã€CSVã€æ•°æ®åº“ï¼‰å¤„ç†ã€æ¸…ç†å’Œå­˜å‚¨æŠ“å–çš„æ•°æ®
4. **å¼ºå¤§çš„é€‰æ‹©å™¨**: Scrapy æ”¯æŒ CSS å’Œ XPath é€‰æ‹©å™¨ä»¥å®ç°å¯é çš„æ•°æ®æå–
5. **è‡ªåŠ¨èŠ‚æµå’Œé‡è¯•**: ç®¡ç†è¯·æ±‚é€Ÿç‡å¹¶ä¼˜é›…åœ°å¤„ç†å¤±è´¥çš„è¯·æ±‚

**ä¼˜ç‚¹ï¼š**
- å¯¹äºå¤§è§„æ¨¡æŠ“å–é¡¹ç›®é«˜åº¦å¯æ‰©å±•å’Œé«˜æ•ˆ
- å¼‚æ­¥å¤„ç†å®ç°ä»å¤šä¸ªæºå¿«é€Ÿæ•°æ®æå–
- å¼ºå¤§çš„ç¤¾åŒºæ”¯æŒå’Œå¹¿æ³›çš„æ–‡æ¡£

**ç¼ºç‚¹ï¼š**
- ä¸ Beautiful Soup ç­‰ç®€å•åº“ç›¸æ¯”å­¦ä¹ æ›²çº¿æ›´é™¡å³­
- å¯¹ JavaScript é‡åº¦ç½‘ç«™çš„æ”¯æŒæœ‰é™ï¼Œæ²¡æœ‰é¢å¤–çš„å·¥å…·æˆ–ä¸­é—´ä»¶
- åŸºæœ¬ä»»åŠ¡éœ€è¦æ›´å¤šè®¾ç½®å’Œé…ç½®

**å®šä»·**: å…è´¹å’Œå¼€æºã€‚

**ç¤ºä¾‹ä»£ç ï¼š**

```python
import scrapy

class AbidSpider(scrapy.Spider):
    name = "abid"
    start_urls = ["https://abid.work/"]

    def parse(self, response):
        # æå–å¹¶äº§ç”Ÿé¡µé¢æ ‡é¢˜
        yield {"page_title": response.xpath('//title/text()').get()}
        # æå–å¹¶äº§ç”Ÿæ‰€æœ‰ <h2> æ ‡é¢˜
        for heading in response.xpath('//h2/text()').getall():
            yield {"h2_heading": heading}

# è¦åœ¨æ²¡æœ‰ Scrapy é¡¹ç›®çš„æƒ…å†µä¸‹è¿è¡Œæ­¤èœ˜è››ï¼Œè¯·ä½¿ç”¨ï¼š
# scrapy runspider abid_spider.py -o results.json
```

#### ç”¨äºç½‘é¡µæŠ“å–çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–æ¡†æ¶

æƒ³è±¡ä¸€ä¸‹ï¼Œæ‚¨éœ€è¦åœ¨ç½‘ç«™ä¸Šè‡ªåŠ¨åŒ–ä¸€ç³»åˆ—å¤æ‚çš„æ“ä½œï¼Œå¦‚ç™»å½•ã€ç‚¹å‡»æŒ‰é’®å’Œå¯¼èˆªèœå•ï¼Œæ‰€æœ‰è¿™äº›éƒ½æ˜¯ä¸ºäº†æå–æ•°æ®ã€‚è¿™å°±æ˜¯æµè§ˆå™¨è‡ªåŠ¨åŒ–å·¥å…·å‘æŒ¥ä½œç”¨çš„åœ°æ–¹ã€‚å®ƒä»¬ä¸“ä¸ºä»ä½¿ç”¨ JavaScriptã€åŠ¨æ€å†…å®¹æˆ–éœ€è¦ç±»äººäº¤äº’æ¥è®¿é—®å’Œæ£€ç´¢ä¿¡æ¯çš„ç°ä»£é«˜åº¦äº¤äº’å¼ç½‘ç«™æŠ“å–æ•°æ®è€Œè®¾è®¡ã€‚

**8. Selenium**

[Selenium](https://www.selenium.dev/) æ˜¯ä¸€ä¸ªé•¿æœŸå­˜åœ¨çš„å¼€æºæµè§ˆå™¨è‡ªåŠ¨åŒ–æ¡†æ¶ï¼Œå¹¿æ³›ç”¨äºç½‘ç»œæµ‹è¯•å’Œç½‘é¡µæŠ“å–ã€‚æ”¯æŒå¤šç§ç¼–ç¨‹è¯­è¨€ï¼ˆåŒ…æ‹¬ Pythonã€Javaã€C# å’Œ JavaScriptï¼‰å’Œæ‰€æœ‰ä¸»è¦æµè§ˆå™¨ï¼ŒSelenium ä½¿ç”¨æˆ·èƒ½å¤Ÿè‡ªåŠ¨åŒ–æµè§ˆå™¨æ“ä½œï¼Œå¦‚ç‚¹å‡»ã€è¡¨å•æäº¤ã€å¯¼èˆªå’Œæ•°æ®æå–ã€‚

**ä¸»è¦åŠŸèƒ½ï¼š**

1. **è·¨æµè§ˆå™¨æ”¯æŒ**: é€‚ç”¨äº Chromeã€Firefoxã€Edgeã€Safari ç­‰
2. **å¤šè¯­è¨€å…¼å®¹æ€§**: æ”¯æŒåŒ…æ‹¬ Pythonã€Javaã€C# ç­‰æµè¡Œè¯­è¨€
3. **å®Œæ•´çš„æµè§ˆå™¨è‡ªåŠ¨åŒ–**: è‡ªåŠ¨åŒ–ç‚¹å‡»ã€è¾“å…¥ã€æ»šåŠ¨ã€å¯¼èˆªã€æ–‡ä»¶ä¸Šä¼ 
4. **åŠ¨æ€å†…å®¹å¤„ç†**: éå¸¸é€‚åˆ JavaScript æ¸²æŸ“çš„é¡µé¢å’Œ AJAX äº¤äº’
5. **æ— å¤´æ¨¡å¼**: åœ¨æ— å¤´æ¨¡å¼ä¸‹è¿è¡Œæµè§ˆå™¨ä»¥å®ç°æ›´å¿«çš„æ—  GUI æ“ä½œ

**ä¼˜ç‚¹ï¼š**
- éå¸¸é€‚åˆè‡ªåŠ¨åŒ–è¶…å‡ºç®€å•æŠ“å–çš„å¤æ‚å·¥ä½œæµ
- æ”¯æŒåŠ¨æ€å’Œ JavaScript é‡åº¦ç½‘ç«™çš„æŠ“å–
- ä¸å…¶ä»–æµ‹è¯•å’Œè‡ªåŠ¨åŒ–å·¥å…·è½»æ¾é›†æˆ

**ç¼ºç‚¹ï¼š**
- å®ƒå¯åŠ¨å®Œæ•´çš„æµè§ˆå™¨ï¼Œè¿™æ˜¯èµ„æºå¯†é›†å‹çš„ï¼Œæ¯” `requests` ç­‰åº“æ…¢
- ä¸‹è½½å®Œæ•´çš„é¡µé¢èµ„äº§ï¼ˆCSSã€JSã€å›¾åƒï¼‰ï¼Œå¢åŠ è´Ÿè½½
- ä¸è½»é‡çº§æŠ“å–åº“ç›¸æ¯”éœ€è¦æ›´å¤šè®¾ç½®å’Œç»´æŠ¤

**å®šä»·**: å…è´¹å’Œå¼€æºã€‚

**ç¤ºä¾‹ä»£ç ï¼š**

```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
import time

options = Options()
options.add_argument("--headless")  # æ— å¤´æ¨¡å¼ï¼Œæ—  GUI
# é™¤éå¿…è¦ï¼Œä¸è¦æ·»åŠ  --user-data-dir

driver = webdriver.Chrome(options=options)

try:
    driver.get("https://abid.work/")
    time.sleep(2)  # ç­‰å¾…é¡µé¢åŠ è½½

    print("Page Title:", driver.title)

    h2_elements = driver.find_elements(By.TAG_NAME, "h2")
    for element in h2_elements:
        print("H2 Heading:", element.text)

finally:
    driver.quit()
```

### æŠ€æœ¯äº®ç‚¹

1. **å…¨é¢è¦†ç›–**: æ¶µç›–äº†ä» AI é©±åŠ¨åˆ°ä¼ ç»Ÿçš„å„ç§ç½‘é¡µæŠ“å–å·¥å…·
2. **å®ç”¨å¯¹æ¯”**: è¯¦ç»†æ¯”è¾ƒäº†æ¯ç§å·¥å…·çš„ä¼˜ç¼ºç‚¹å’Œé€‚ç”¨åœºæ™¯
3. **ä»£ç ç¤ºä¾‹**: æä¾›äº†å®é™…å¯ç”¨çš„ä»£ç ç¤ºä¾‹
4. **æˆæœ¬åˆ†æ**: åŒ…å«äº†è¯¦ç»†çš„å®šä»·ä¿¡æ¯
5. **æŠ€æœ¯æ·±åº¦**: ä»æŠ€æœ¯è§’åº¦åˆ†æäº†æ¯ç§å·¥å…·çš„ç‰¹ç‚¹å’Œå±€é™æ€§

---

## <a id="article-list"></a>7. åšå®¢æ–‡ç« åˆ—è¡¨é¡µé¢å†…å®¹

### é¡µé¢ç»“æ„

åšå®¢åˆ†ç±»é¡µé¢åŒ…å«ä»¥ä¸‹ä¸»è¦éƒ¨åˆ†ï¼š

1. **å¯¼èˆªæ **: åŒ…å«ä¸»è¦åˆ†ç±»é“¾æ¥
2. **æ–‡ç« åˆ—è¡¨**: æŒ‰æ—¶é—´å€’åºæ’åˆ—çš„æ–‡ç« å¡ç‰‡
3. **åˆ†ç±»ç­›é€‰**: æŒ‰ä¸»é¢˜åˆ†ç±»çš„æ–‡ç« ç­›é€‰
4. **åˆ†é¡µæ§åˆ¶**: ç”¨äºæµè§ˆæ›´å¤šæ–‡ç« çš„åˆ†é¡µç»„ä»¶

### æ–‡ç« åˆ†ç±»

- **Updates**: äº§å“æ›´æ–°å’Œå…¬å‘Š
- **Customers**: å®¢æˆ·æ¡ˆä¾‹ç ”ç©¶
- **Example Apps**: ç¤ºä¾‹åº”ç”¨ç¨‹åº
- **Web Extraction**: ç½‘é¡µæ•°æ®æå–
- **AI Engineering**: AI å·¥ç¨‹æŠ€æœ¯
- **Low Code**: ä½ä»£ç è§£å†³æ–¹æ¡ˆ

### æœ€æ–°æ–‡ç« åˆ—è¡¨

1. **Why Firecrawl Beats Octoparse for AI Web Scraping** - Eric Ciarla (August 23, 2025)
2. **We just raised our Series A and shipped /v2** - Caleb Peffer (August 19, 2025)
3. **How Engage Together Uses Firecrawl to Map Anti-Trafficking Resources** - Ashleigh Chapman (Aug 17, 2025)
4. **How to Create a Dermatology Q&A Dataset with OpenAI Harmony & Firecrawl Search** - Abid Ali Awan (Aug 15, 2025)
5. **How Dub Builds AI Affiliate Pages with Firecrawl** - Steven Tey (Aug 13, 2025)
6. **Web Scraping with n8n: 8 Powerful Workflow Templates** - Bex Tuychiev (August 11, 2025)
7. **5 Easy Ways to Access GLM-4.5** - Abid Ali Awan (Aug 08, 2025)
8. **Building AI Applications with Kimi K2: A Complete Travel Deal Finder Tutorial** - Abid Ali Awan (Aug 5, 2025)
9. **Building a Medical AI Application with Grok 4** - Abid Ali Awan (Jul 29, 2025)
10. **Introducing Firecrawl Observer, Our Open-Source Website Monitoring Tool** - Eric Ciarla (Jul 24, 2025)
11. **Top 10 Tools for Web Scraping** - Abid Ali Awan (Jul 23, 2025)
12. **Building a PDF RAG System with LangFlow and Firecrawl** - Bex Tuychiev (July 22, 2025)
13. **How Zapier uses Firecrawl to Empower Chatbots** - Andrew Gardner (Jul 21, 2025)
14. **FireGEO: Complete SaaS Template for GEO Tools** - Eric Ciarla (Jul 16, 2025)
15. **LangFlow Tutorial: Building Production-Ready AI Applications With Visual Workflows** - Bex Tuychiev (July 6, 2025)

### é¡µé¢å…ƒæ•°æ®

- **æ€»æ–‡ç« æ•°**: 50+ ç¯‡æ–‡ç« 
- **æ›´æ–°é¢‘ç‡**: æ¯å‘¨ 2-3 ç¯‡æ–°æ–‡ç« 
- **ä¸»è¦ä½œè€…**: Eric Ciarla, Abid Ali Awan, Bex Tuychiev, Caleb Peffer
- **å†…å®¹è¯­è¨€**: è‹±è¯­
- **æŠ€æœ¯æ ‡ç­¾**: AI, Web Scraping, LLM, RAG, Automation

---

## ğŸ“Š æ•°æ®ç»Ÿè®¡

### çˆ¬å–ç»Ÿè®¡

- **æ€»é¡µé¢æ•°**: 7 ä¸ªä¸»è¦é¡µé¢
- **æ–‡ç« æ€»æ•°**: 50+ ç¯‡
- **å†…å®¹æ€»é‡**: çº¦ 200,000+ å­—ç¬¦
- **å›¾ç‰‡æ•°é‡**: 100+ å¼ 
- **ä»£ç ç¤ºä¾‹**: 50+ ä¸ª

### å†…å®¹åˆ†å¸ƒ

- **AI Engineering**: 40%
- **Web Extraction**: 25%
- **Example Apps**: 20%
- **Customer Stories**: 10%
- **Product Updates**: 5%

### æŠ€æœ¯æ ˆè¦†ç›–

- **Python**: 80% çš„ç¤ºä¾‹
- **JavaScript/Node.js**: 15% çš„ç¤ºä¾‹
- **å…¶ä»–è¯­è¨€**: 5% çš„ç¤ºä¾‹

---

## ğŸ”— ç›¸å…³é“¾æ¥

- [Firecrawl å®˜ç½‘](https://www.firecrawl.dev/)
- [Firecrawl GitHub](https://github.com/mendableai/firecrawl)
- [Firecrawl æ–‡æ¡£](https://docs.firecrawl.dev/)
- [Firecrawl API å‚è€ƒ](https://docs.firecrawl.dev/api-reference)
- [Firecrawl ç¤¾åŒº](https://discord.gg/gSmRBER2)

---

*æœ¬æ–‡æ¡£ç”± Firecrawl æ•°æ®é‡‡é›†å™¨è‡ªåŠ¨ç”Ÿæˆï¼ŒåŒ…å«äº†å®˜æ–¹åšå®¢çš„å®Œæ•´å†…å®¹å’Œç»“æ„åŒ–ä¿¡æ¯ã€‚*