#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¿«é€Ÿæµ‹è¯•è„šæœ¬ - ä½¿ç”¨Firecrawl v2 APIæ‰¹é‡é‡‡é›†ä»Šæ—¥å¤´æ¡æ–°é—»
"""

import requests
import json
import time

def quick_test_batch_scrape():
    """å¿«é€Ÿæµ‹è¯•æ‰¹é‡æŠ“å–åŠŸèƒ½"""
    
    # é…ç½®
    API_KEY = "fc-0a2c801f433d4718bcd8189f2742edf4"
    headers = {
        "Authorization": f"Bearer {API_KEY}",
        "Content-Type": "application/json"
    }
    
    print("ğŸ”¥ Firecrawl v2 æ‰¹é‡æŠ“å–å¿«é€Ÿæµ‹è¯•")
    print("=" * 50)
    
    # 1. å…ˆæœç´¢è·å–URLåˆ—è¡¨
    print("\nğŸ“° æ­¥éª¤1: æœç´¢ä»Šæ—¥å¤´æ¡æ–°é—»")
    search_payload = {
        "query": "ä»Šæ—¥å¤´æ¡ ç§‘æŠ€æ–°é—»",
        "limit": 3,
        "scrapeOptions": {
            "formats": ["markdown"],
            "onlyMainContent": True,
            "waitFor": 3000
        }
    }
    
    try:
        response = requests.post(
            "https://api.firecrawl.dev/v2/search",
            json=search_payload,
            headers=headers
        )
        
        if response.status_code == 200:
            data = response.json()
            urls = [item['url'] for item in data.get('data', []) if item.get('url')]
            print(f"âœ… æœç´¢æˆåŠŸï¼Œæ‰¾åˆ° {len(urls)} ä¸ªURL")
            
            for i, url in enumerate(urls, 1):
                print(f"  {i}. {url}")
                
        else:
            print(f"âŒ æœç´¢å¤±è´¥: {response.status_code}")
            return
            
    except Exception as e:
        print(f"âŒ æœç´¢é”™è¯¯: {e}")
        return
    
    if not urls:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„URL")
        return
    
    # 2. æ‰¹é‡æŠ“å–
    print(f"\nğŸ“„ æ­¥éª¤2: æ‰¹é‡æŠ“å– {len(urls)} ä¸ªURL")
    
    batch_payload = {
        "urls": urls,
        "maxConcurrency": 2,  # æ§åˆ¶å¹¶å‘æ•°
        "ignoreInvalidURLs": True,
        "formats": ["markdown"],
        "onlyMainContent": True,
        "waitFor": 5000,  # ç­‰å¾…JSæ¸²æŸ“
        "timeout": 30,
        "removeBase64Images": True,
        "blockAds": True,
        "location": {
            "country": "CN",
            "languages": ["zh-CN"]
        }
    }
    
    try:
        response = requests.post(
            "https://api.firecrawl.dev/v2/batch/scrape",
            json=batch_payload,
            headers=headers
        )
        
        if response.status_code == 200:
            result = response.json()
            task_id = result.get('id')
            print(f"âœ… æ‰¹é‡æŠ“å–ä»»åŠ¡å·²æäº¤")
            print(f"ä»»åŠ¡ID: {task_id}")
            
            # 3. ç­‰å¾…å¹¶æ£€æŸ¥çŠ¶æ€
            print(f"\nâ³ æ­¥éª¤3: ç­‰å¾…ä»»åŠ¡å®Œæˆ...")
            
            for attempt in range(30):  # æœ€å¤šç­‰å¾…5åˆ†é’Ÿ
                time.sleep(10)
                
                status_response = requests.get(
                    f"https://api.firecrawl.dev/v2/batch/scrape/{task_id}",
                    headers=headers
                )
                
                if status_response.status_code == 200:
                    status_data = status_response.json()
                    task_status = status_data.get('status')
                    
                    print(f"  çŠ¶æ€æ£€æŸ¥ {attempt + 1}: {task_status}")
                    
                    if task_status == 'completed':
                        print("âœ… ä»»åŠ¡å®Œæˆ!")
                        
                        # 4. è·å–ç»“æœ
                        print(f"\nğŸ“Š æ­¥éª¤4: è·å–é‡‡é›†ç»“æœ")
                        
                        successful_results = []
                        for item in status_data.get('data', []):
                            if item.get('success'):
                                successful_results.append({
                                    'url': item.get('url'),
                                    'title': item.get('title'),
                                    'content_length': len(item.get('markdown', '')),
                                    'content_preview': item.get('markdown', '')[:200] + '...'
                                })
                        
                        print(f"âœ… æˆåŠŸé‡‡é›† {len(successful_results)} æ¡æ–°é—»")
                        
                        for i, result in enumerate(successful_results, 1):
                            print(f"\nğŸ“° æ–°é—» {i}:")
                            print(f"  æ ‡é¢˜: {result['title']}")
                            print(f"  URL: {result['url']}")
                            print(f"  å†…å®¹é•¿åº¦: {result['content_length']} å­—ç¬¦")
                            print(f"  å†…å®¹é¢„è§ˆ: {result['content_preview']}")
                        
                        # ä¿å­˜ç»“æœ
                        timestamp = time.strftime("%Y%m%d_%H%M%S")
                        filename = f"quick_test_results_{timestamp}.json"
                        
                        with open(filename, 'w', encoding='utf-8') as f:
                            json.dump(successful_results, f, ensure_ascii=False, indent=2)
                        
                        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {filename}")
                        break
                        
                    elif task_status == 'failed':
                        print("âŒ ä»»åŠ¡å¤±è´¥")
                        break
                        
                else:
                    print(f"âŒ çŠ¶æ€æŸ¥è¯¢å¤±è´¥: {status_response.status_code}")
                    break
            else:
                print("â° ç­‰å¾…è¶…æ—¶")
                
        else:
            print(f"âŒ æ‰¹é‡æŠ“å–å¤±è´¥: {response.status_code}")
            print(f"é”™è¯¯ä¿¡æ¯: {response.text[:300]}")
            
    except Exception as e:
        print(f"âŒ æ‰¹é‡æŠ“å–é”™è¯¯: {e}")

if __name__ == "__main__":
    quick_test_batch_scrape()
