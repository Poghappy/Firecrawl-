#!/bin/bash
# Firecrawl v2 ç»Ÿä¸€æ–°é—»é‡‡é›†å™¨ - ç”Ÿäº§çŽ¯å¢ƒéƒ¨ç½²è„šæœ¬

set -e

echo "ðŸš€ Firecrawl v2 ç»Ÿä¸€æ–°é—»é‡‡é›†å™¨ - ç”Ÿäº§çŽ¯å¢ƒéƒ¨ç½²"
echo "=================================================="

# æ£€æŸ¥çŽ¯å¢ƒå˜é‡
if [ -z "$FIRECRAWL_API_KEY" ]; then
    echo "âŒ é”™è¯¯: è¯·è®¾ç½®FIRECRAWL_API_KEYçŽ¯å¢ƒå˜é‡"
    echo "ä¾‹å¦‚: export FIRECRAWL_API_KEY='your-api-key'"
    exit 1
fi

echo "âœ… çŽ¯å¢ƒå˜é‡æ£€æŸ¥é€šè¿‡"

# åˆ›å»ºå¿…è¦çš„ç›®å½•
echo "ðŸ“ åˆ›å»ºå¿…è¦çš„ç›®å½•..."
mkdir -p data logs results config/prometheus config/grafana

# åˆ›å»ºçŽ¯å¢ƒå˜é‡æ–‡ä»¶
echo "ðŸ”§ åˆ›å»ºçŽ¯å¢ƒå˜é‡æ–‡ä»¶..."
cat > .env << EOF
FIRECRAWL_API_KEY=${FIRECRAWL_API_KEY}
LOG_LEVEL=INFO
TZ=Asia/Shanghai
EOF

# åˆ›å»ºPrometheusé…ç½®
echo "ðŸ“Š åˆ›å»ºPrometheusé…ç½®..."
cat > config/prometheus/prometheus.yml << EOF
global:
  scrape_interval: 15s
  evaluation_interval: 15s

rule_files:
  # - "first_rules.yml"
  # - "second_rules.yml"

scrape_configs:
  - job_name: 'firecrawl-scraper'
    static_configs:
      - targets: ['firecrawl-scraper:8000']
    scrape_interval: 30s
    metrics_path: /metrics

  - job_name: 'prometheus'
    static_configs:
      - targets: ['localhost:9090']
EOF

# åˆ›å»ºGrafanaé…ç½®
echo "ðŸ“ˆ åˆ›å»ºGrafanaé…ç½®..."
mkdir -p config/grafana/datasources
cat > config/grafana/datasources/prometheus.yml << EOF
apiVersion: 1

datasources:
  - name: Prometheus
    type: prometheus
    access: proxy
    url: http://prometheus:9090
    isDefault: true
    editable: true
EOF

# æž„å»ºDockeré•œåƒ
echo "ðŸ”¨ æž„å»ºDockeré•œåƒ..."
docker build -f Dockerfile.production -t firecrawl-v2-scraper:latest .

# åœæ­¢çŽ°æœ‰å®¹å™¨
echo "ðŸ›‘ åœæ­¢çŽ°æœ‰å®¹å™¨..."
docker-compose -f docker-compose.production.yml down || true

# å¯åŠ¨æœåŠ¡
echo "ðŸš€ å¯åŠ¨ç”Ÿäº§çŽ¯å¢ƒæœåŠ¡..."
docker-compose -f docker-compose.production.yml up -d

# ç­‰å¾…æœåŠ¡å¯åŠ¨
echo "â³ ç­‰å¾…æœåŠ¡å¯åŠ¨..."
sleep 30

# æ£€æŸ¥æœåŠ¡çŠ¶æ€
echo "ðŸ” æ£€æŸ¥æœåŠ¡çŠ¶æ€..."
docker-compose -f docker-compose.production.yml ps

# è¿è¡Œæµ‹è¯•
echo "ðŸ§ª è¿è¡ŒåŠŸèƒ½æµ‹è¯•..."
docker-compose -f docker-compose.production.yml exec firecrawl-scraper python -c "
import sys
sys.path.append('/app')
from firecrawl_v2_unified_scraper import FirecrawlV2UnifiedScraper
import os

# æµ‹è¯•APIè¿žæŽ¥
scraper = FirecrawlV2UnifiedScraper()
results = scraper.search_news_v2('äººå·¥æ™ºèƒ½ æ–°é—»', limit=2)
print(f'âœ… APIè¿žæŽ¥æµ‹è¯•æˆåŠŸ: æ‰¾åˆ° {len(results)} æ¡ç»“æžœ')
"

# æ˜¾ç¤ºè®¿é—®ä¿¡æ¯
echo ""
echo "ðŸŽ‰ éƒ¨ç½²å®Œæˆ!"
echo "=================================================="
echo "ðŸ“Š ç›‘æŽ§é¢æ¿:"
echo "  - Grafana: http://localhost:3000 (admin/admin123)"
echo "  - Prometheus: http://localhost:9090"
echo ""
echo "ðŸ“ æ—¥å¿—æŸ¥çœ‹:"
echo "  docker-compose -f docker-compose.production.yml logs -f firecrawl-scraper"
echo ""
echo "ðŸ”„ é‡å¯æœåŠ¡:"
echo "  docker-compose -f docker-compose.production.yml restart"
echo ""
echo "ðŸ›‘ åœæ­¢æœåŠ¡:"
echo "  docker-compose -f docker-compose.production.yml down"
echo ""
echo "ðŸ“ æ•°æ®ç›®å½•:"
echo "  - é‡‡é›†ç»“æžœ: ./results/"
echo "  - æ—¥å¿—æ–‡ä»¶: ./logs/"
echo "  - æ•°æ®æ–‡ä»¶: ./data/"
echo "=================================================="
