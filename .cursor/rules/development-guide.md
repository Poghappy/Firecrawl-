# å¼€å‘æŒ‡å—

## ğŸš€ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒå‡†å¤‡
```bash
# 1. å…‹éš†é¡¹ç›®
git clone <repository-url>
cd Firecrawlæ•°æ®é‡‡é›†å™¨

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥å¿…è¦çš„é…ç½®

# 5. åˆå§‹åŒ–æ•°æ®åº“
python scripts/init-db.py

# 6. è¿è¡Œæµ‹è¯•
pytest tests/

# 7. å¯åŠ¨å¼€å‘æœåŠ¡å™¨
python -m uvicorn src.api_server:app --reload
```

### å¼€å‘ç¯å¢ƒé…ç½®
```bash
# ä½¿ç”¨Docker Composeå¯åŠ¨å¼€å‘ç¯å¢ƒ
docker-compose -f config/deployment/docker-compose.yml up -d

# æŸ¥çœ‹æœåŠ¡çŠ¶æ€
docker-compose ps

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f app
```

## ğŸ—ï¸ é¡¹ç›®æ¶æ„

### æ ¸å¿ƒæ¨¡å—
```
src/
â”œâ”€â”€ collectors/          # æ•°æ®é‡‡é›†æ¨¡å—
â”‚   â”œâ”€â”€ firecrawl_collector.py
â”‚   â”œâ”€â”€ base_collector.py
â”‚   â””â”€â”€ custom_collectors/
â”œâ”€â”€ processors/          # æ•°æ®å¤„ç†æ¨¡å—
â”‚   â”œâ”€â”€ data_processor.py
â”‚   â”œâ”€â”€ content_cleaner.py
â”‚   â””â”€â”€ ai_processor.py
â”œâ”€â”€ models/             # æ•°æ®æ¨¡å‹
â”‚   â”œâ”€â”€ database_models.py
â”‚   â”œâ”€â”€ api_models.py
â”‚   â””â”€â”€ domain_models.py
â”œâ”€â”€ api/                # APIæ¥å£
â”‚   â”œâ”€â”€ api_server.py
â”‚   â”œâ”€â”€ routes/
â”‚   â””â”€â”€ middleware/
â”œâ”€â”€ services/           # ä¸šåŠ¡æœåŠ¡
â”‚   â”œâ”€â”€ collection_service.py
â”‚   â”œâ”€â”€ processing_service.py
â”‚   â””â”€â”€ notification_service.py
â”œâ”€â”€ utils/              # å·¥å…·å‡½æ•°
â”‚   â”œâ”€â”€ logging_utils.py
â”‚   â”œâ”€â”€ validation_utils.py
â”‚   â””â”€â”€ crypto_utils.py
â””â”€â”€ config/             # é…ç½®ç®¡ç†
    â”œâ”€â”€ settings.py
    â”œâ”€â”€ database.py
    â””â”€â”€ redis.py
```

### æ•°æ®æµæ¶æ„
```mermaid
graph TD
    A[URLè¾“å…¥] --> B[é‡‡é›†å™¨]
    B --> C[æ•°æ®éªŒè¯]
    C --> D[å†…å®¹æ¸…æ´—]
    D --> E[AIåˆ†æ]
    E --> F[æ•°æ®å­˜å‚¨]
    F --> G[é€šçŸ¥ç³»ç»Ÿ]
    G --> H[APIè¾“å‡º]
```

## ğŸ”§ å¼€å‘è§„èŒƒ

### ä»£ç ç»“æ„è§„èŒƒ
```python
# æ–‡ä»¶å¤´éƒ¨æ³¨é‡Š
"""
æ¨¡å—åç§°: firecrawl_collector.py
æè¿°: Firecrawlæ•°æ®é‡‡é›†å™¨æ ¸å¿ƒæ¨¡å—
ä½œè€…: AIå…¨æ ˆå·¥ç¨‹å¸ˆ
åˆ›å»ºæ—¶é—´: 2024-09-21
ç‰ˆæœ¬: v1.0.0
"""

# å¯¼å…¥é¡ºåº
import os
import sys
from typing import Dict, List, Optional, Any
from datetime import datetime
import logging

import requests
import pandas as pd
from fastapi import FastAPI, HTTPException
from sqlalchemy import create_engine

from src.config.settings import Settings
from src.utils.logging_utils import get_logger

# å¸¸é‡å®šä¹‰
DEFAULT_TIMEOUT = 30
MAX_RETRIES = 3
SUPPORTED_FORMATS = ['json', 'xml', 'html']

# æ—¥å¿—é…ç½®
logger = get_logger(__name__)

# ç±»å®šä¹‰
class FirecrawlCollector:
    """Firecrawlæ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, config: Dict[str, Any]):
        """åˆå§‹åŒ–é‡‡é›†å™¨
        
        Args:
            config: é…ç½®å­—å…¸
        """
        self.config = config
        self.session = requests.Session()
        logger.info("FirecrawlCollector initialized")

# å‡½æ•°å®šä¹‰
async def collect_data(url: str, options: Dict[str, Any]) -> Dict[str, Any]:
    """é‡‡é›†æ•°æ®
    
    Args:
        url: ç›®æ ‡URL
        options: é‡‡é›†é€‰é¡¹
        
    Returns:
        Dict[str, Any]: é‡‡é›†ç»“æœ
        
    Raises:
        ValueError: URLæ ¼å¼é”™è¯¯
        requests.RequestException: ç½‘ç»œè¯·æ±‚å¤±è´¥
    """
    # å®ç°é€»è¾‘
    pass

# ä¸»ç¨‹åºå…¥å£
if __name__ == "__main__":
    # ä¸»ç¨‹åºé€»è¾‘
    pass
```

### APIå¼€å‘è§„èŒƒ
```python
from fastapi import FastAPI, HTTPException, Depends
from pydantic import BaseModel, Field
from typing import List, Optional
import logging

app = FastAPI(title="Firecrawlæ•°æ®é‡‡é›†å™¨API", version="1.0.0")

class CollectRequest(BaseModel):
    """é‡‡é›†è¯·æ±‚æ¨¡å‹"""
    url: str = Field(..., description="ç›®æ ‡URL", example="https://example.com")
    options: Optional[Dict[str, Any]] = Field(default={}, description="é‡‡é›†é€‰é¡¹")
    
    class Config:
        schema_extra = {
            "example": {
                "url": "https://example.com",
                "options": {
                    "format": "json",
                    "timeout": 30
                }
            }
        }

class CollectResponse(BaseModel):
    """é‡‡é›†å“åº”æ¨¡å‹"""
    success: bool = Field(..., description="æ˜¯å¦æˆåŠŸ")
    data: Optional[Dict[str, Any]] = Field(None, description="é‡‡é›†æ•°æ®")
    error: Optional[str] = Field(None, description="é”™è¯¯ä¿¡æ¯")
    timestamp: datetime = Field(default_factory=datetime.utcnow, description="æ—¶é—´æˆ³")

@app.post("/api/v1/collect", response_model=CollectResponse)
async def collect_endpoint(
    request: CollectRequest,
    collector: FirecrawlCollector = Depends(get_collector)
) -> CollectResponse:
    """æ•°æ®é‡‡é›†ç«¯ç‚¹
    
    Args:
        request: é‡‡é›†è¯·æ±‚
        collector: é‡‡é›†å™¨å®ä¾‹
        
    Returns:
        CollectResponse: é‡‡é›†ç»“æœ
    """
    try:
        logger.info(f"Collecting data from {request.url}")
        
        result = await collector.collect(request.url, request.options)
        
        return CollectResponse(
            success=True,
            data=result,
            timestamp=datetime.utcnow()
        )
        
    except ValueError as e:
        logger.error(f"Invalid request: {e}")
        raise HTTPException(status_code=400, detail=str(e))
        
    except Exception as e:
        logger.error(f"Collection failed: {e}")
        raise HTTPException(status_code=500, detail="Internal server error")
```

### æ•°æ®åº“æ“ä½œè§„èŒƒ
```python
from sqlalchemy import Column, Integer, String, DateTime, Text, Boolean
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
from sqlalchemy import create_engine
from datetime import datetime

Base = declarative_base()

class CollectionRecord(Base):
    """é‡‡é›†è®°å½•æ¨¡å‹"""
    __tablename__ = "collection_records"
    
    id = Column(Integer, primary_key=True, index=True)
    url = Column(String(500), nullable=False, index=True)
    status = Column(String(50), nullable=False, default="pending")
    content = Column(Text, nullable=True)
    metadata = Column(Text, nullable=True)  # JSONå­—ç¬¦ä¸²
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)
    is_active = Column(Boolean, default=True)

class DatabaseService:
    """æ•°æ®åº“æœåŠ¡ç±»"""
    
    def __init__(self, database_url: str):
        self.engine = create_engine(database_url)
        self.SessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=self.engine)
        Base.metadata.create_all(bind=self.engine)
    
    def get_session(self):
        """è·å–æ•°æ®åº“ä¼šè¯"""
        return self.SessionLocal()
    
    async def create_record(self, url: str, content: str, metadata: Dict[str, Any]) -> CollectionRecord:
        """åˆ›å»ºé‡‡é›†è®°å½•"""
        with self.get_session() as session:
            record = CollectionRecord(
                url=url,
                content=content,
                metadata=json.dumps(metadata),
                status="completed"
            )
            session.add(record)
            session.commit()
            session.refresh(record)
            return record
    
    async def get_records(self, limit: int = 100, offset: int = 0) -> List[CollectionRecord]:
        """è·å–é‡‡é›†è®°å½•"""
        with self.get_session() as session:
            return session.query(CollectionRecord)\
                         .filter(CollectionRecord.is_active == True)\
                         .offset(offset)\
                         .limit(limit)\
                         .all()
```

## ğŸ§ª æµ‹è¯•å¼€å‘

### å•å…ƒæµ‹è¯•è§„èŒƒ
```python
import pytest
from unittest.mock import Mock, patch, AsyncMock
from datetime import datetime
from src.collectors.firecrawl_collector import FirecrawlCollector
from src.models.database_models import CollectionRecord

class TestFirecrawlCollector:
    """FirecrawlCollectoræµ‹è¯•ç±»"""
    
    @pytest.fixture
    def collector(self):
        """é‡‡é›†å™¨æµ‹è¯•å¤¹å…·"""
        config = {
            "api_key": "test_api_key",
            "base_url": "https://api.firecrawl.dev",
            "timeout": 30
        }
        return FirecrawlCollector(config)
    
    @pytest.fixture
    def sample_url(self):
        """ç¤ºä¾‹URL"""
        return "https://example.com"
    
    @pytest.fixture
    def sample_response(self):
        """ç¤ºä¾‹å“åº”æ•°æ®"""
        return {
            "success": True,
            "data": {
                "url": "https://example.com",
                "title": "Example Domain",
                "content": "This domain is for use in illustrative examples",
                "metadata": {
                    "status_code": 200,
                    "content_type": "text/html"
                }
            }
        }
    
    @pytest.mark.asyncio
    async def test_collect_success(self, collector, sample_url, sample_response):
        """æµ‹è¯•æˆåŠŸé‡‡é›†æ•°æ®"""
        with patch('requests.Session.get') as mock_get:
            mock_get.return_value.json.return_value = sample_response
            mock_get.return_value.status_code = 200
            
            result = await collector.collect(sample_url)
            
            assert result["success"] is True
            assert result["data"]["url"] == sample_url
            assert "content" in result["data"]
    
    @pytest.mark.asyncio
    async def test_collect_invalid_url(self, collector):
        """æµ‹è¯•æ— æ•ˆURLå¤„ç†"""
        with pytest.raises(ValueError, match="Invalid URL format"):
            await collector.collect("invalid-url")
    
    @pytest.mark.asyncio
    async def test_collect_network_error(self, collector, sample_url):
        """æµ‹è¯•ç½‘ç»œé”™è¯¯å¤„ç†"""
        with patch('requests.Session.get') as mock_get:
            mock_get.side_effect = requests.RequestException("Network error")
            
            with pytest.raises(requests.RequestException):
                await collector.collect(sample_url)
    
    def test_config_validation(self):
        """æµ‹è¯•é…ç½®éªŒè¯"""
        # æµ‹è¯•æœ‰æ•ˆé…ç½®
        valid_config = {
            "api_key": "valid_key",
            "base_url": "https://api.firecrawl.dev"
        }
        collector = FirecrawlCollector(valid_config)
        assert collector.config["api_key"] == "valid_key"
        
        # æµ‹è¯•æ— æ•ˆé…ç½®
        with pytest.raises(ValueError):
            FirecrawlCollector({})

class TestDatabaseService:
    """æ•°æ®åº“æœåŠ¡æµ‹è¯•ç±»"""
    
    @pytest.fixture
    def db_service(self):
        """æ•°æ®åº“æœåŠ¡æµ‹è¯•å¤¹å…·"""
        return DatabaseService("sqlite:///:memory:")
    
    @pytest.mark.asyncio
    async def test_create_record(self, db_service):
        """æµ‹è¯•åˆ›å»ºè®°å½•"""
        url = "https://example.com"
        content = "Test content"
        metadata = {"test": "data"}
        
        record = await db_service.create_record(url, content, metadata)
        
        assert record.url == url
        assert record.content == content
        assert record.status == "completed"
        assert record.id is not None
```

### é›†æˆæµ‹è¯•è§„èŒƒ
```python
import pytest
import httpx
from fastapi.testclient import TestClient
from src.api.api_server import app

class TestAPI:
    """APIé›†æˆæµ‹è¯•ç±»"""
    
    @pytest.fixture
    def client(self):
        """æµ‹è¯•å®¢æˆ·ç«¯"""
        return TestClient(app)
    
    def test_health_check(self, client):
        """æµ‹è¯•å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
        response = client.get("/health")
        assert response.status_code == 200
        assert response.json()["status"] == "healthy"
    
    def test_collect_endpoint(self, client):
        """æµ‹è¯•é‡‡é›†ç«¯ç‚¹"""
        payload = {
            "url": "https://example.com",
            "options": {
                "format": "json",
                "timeout": 30
            }
        }
        
        with patch('src.collectors.firecrawl_collector.FirecrawlCollector.collect') as mock_collect:
            mock_collect.return_value = {
                "success": True,
                "data": {"content": "test content"}
            }
            
            response = client.post("/api/v1/collect", json=payload)
            
            assert response.status_code == 200
            assert response.json()["success"] is True
    
    def test_collect_endpoint_invalid_url(self, client):
        """æµ‹è¯•æ— æ•ˆURLç«¯ç‚¹"""
        payload = {
            "url": "invalid-url",
            "options": {}
        }
        
        response = client.post("/api/v1/collect", json=payload)
        
        assert response.status_code == 400
        assert "Invalid URL" in response.json()["detail"]
```

## ğŸ” è°ƒè¯•æŠ€å·§

### æ—¥å¿—é…ç½®
```python
import logging
import sys
from datetime import datetime

# é…ç½®æ—¥å¿—æ ¼å¼
LOG_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
DATE_FORMAT = "%Y-%m-%d %H:%M:%S"

# é…ç½®æ ¹æ—¥å¿—å™¨
logging.basicConfig(
    level=logging.INFO,
    format=LOG_FORMAT,
    datefmt=DATE_FORMAT,
    handlers=[
        logging.StreamHandler(sys.stdout),
        logging.FileHandler("logs/app.log", encoding="utf-8")
    ]
)

# åˆ›å»ºæ¨¡å—æ—¥å¿—å™¨
logger = logging.getLogger(__name__)

# ä½¿ç”¨ç¤ºä¾‹
logger.info("Application started")
logger.debug("Debug information")
logger.warning("Warning message")
logger.error("Error occurred", exc_info=True)
```

### æ€§èƒ½åˆ†æ
```python
import time
import functools
import cProfile
import pstats
from memory_profiler import profile

def timing_decorator(func):
    """è®¡æ—¶è£…é¥°å™¨"""
    @functools.wraps(func)
    async def wrapper(*args, **kwargs):
        start_time = time.time()
        result = await func(*args, **kwargs)
        end_time = time.time()
        logger.info(f"{func.__name__} took {end_time - start_time:.2f} seconds")
        return result
    return wrapper

@profile
def memory_intensive_function():
    """å†…å­˜å¯†é›†å‹å‡½æ•°"""
    data = []
    for i in range(100000):
        data.append(f"item_{i}")
    return data

def profile_function(func):
    """æ€§èƒ½åˆ†æè£…é¥°å™¨"""
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        profiler = cProfile.Profile()
        profiler.enable()
        
        result = func(*args, **kwargs)
        
        profiler.disable()
        stats = pstats.Stats(profiler)
        stats.sort_stats('cumulative')
        stats.print_stats(10)
        
        return result
    return wrapper
```

## ğŸ“š å¸¸ç”¨å·¥å…·

### ä»£ç è´¨é‡å·¥å…·
```bash
# ä»£ç æ ¼å¼åŒ–
black src/ tests/
isort src/ tests/

# ä»£ç æ£€æŸ¥
flake8 src/ tests/
mypy src/
pylint src/

# å®‰å…¨æ£€æŸ¥
bandit -r src/
safety check

# å¤æ‚åº¦åˆ†æ
radon cc src/ -a
xenon src/ --max-absolute B --max-modules A --max-average A
```

### æµ‹è¯•å·¥å…·
```bash
# è¿è¡Œæµ‹è¯•
pytest tests/ -v --cov=src --cov-report=html

# è¿è¡Œç‰¹å®šæµ‹è¯•
pytest tests/test_collector.py::TestFirecrawlCollector::test_collect_success -v

# ç”Ÿæˆè¦†ç›–ç‡æŠ¥å‘Š
pytest --cov=src --cov-report=term-missing

# æ€§èƒ½æµ‹è¯•
pytest tests/performance/ -v --benchmark-only
```

### éƒ¨ç½²å·¥å…·
```bash
# Dockeræ„å»º
docker build -t firecrawl-collector:latest .

# Docker Composeéƒ¨ç½²
docker-compose -f config/deployment/docker-compose.yml up -d

# å¥åº·æ£€æŸ¥
curl http://localhost:8000/health

# æ—¥å¿—æŸ¥çœ‹
docker-compose logs -f app
```

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0.0  
**æœ€åæ›´æ–°**: 2024-09-21  
**ç»´æŠ¤è€…**: AIå…¨æ ˆå·¥ç¨‹å¸ˆ
