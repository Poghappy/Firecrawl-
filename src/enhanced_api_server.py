#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¢å¼ºç‰ˆAPIæœåŠ¡å™¨
é›†æˆFirecrawl APIï¼Œæä¾›å®Œæ•´çš„æ•°æ®é‡‡é›†æœåŠ¡
"""

import os
import sys
import json
import asyncio
import logging
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

try:
    from firecrawl import FirecrawlApp
    import uvicorn
    from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
    from fastapi.middleware.cors import CORSMiddleware
    from fastapi.responses import JSONResponse
    from pydantic import BaseModel, Field
    from contextlib import asynccontextmanager
except ImportError as e:
    print(f"âŒ ä¾èµ–åŒ…å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·è¿è¡Œ: pip install firecrawl-py fastapi uvicorn")
    sys.exit(1)

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# Pydanticæ¨¡å‹
class CrawlRequest(BaseModel):
    """çˆ¬å–è¯·æ±‚æ¨¡å‹"""
    url: str = Field(..., description="è¦çˆ¬å–çš„URL")
    formats: List[str] = Field(default=["markdown"], description="è¾“å‡ºæ ¼å¼")
    only_main_content: bool = Field(default=True, description="ä»…ä¸»è¦å†…å®¹")
    max_depth: int = Field(default=1, description="æœ€å¤§çˆ¬å–æ·±åº¦")
    timeout: int = Field(default=30, description="è¶…æ—¶æ—¶é—´(ç§’)")

class CrawlResponse(BaseModel):
    """çˆ¬å–å“åº”æ¨¡å‹"""
    success: bool
    url: str
    content: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    timestamp: str
    processing_time: float

class BatchCrawlRequest(BaseModel):
    """æ‰¹é‡çˆ¬å–è¯·æ±‚æ¨¡å‹"""
    urls: List[str] = Field(..., description="è¦çˆ¬å–çš„URLåˆ—è¡¨")
    formats: List[str] = Field(default=["markdown"], description="è¾“å‡ºæ ¼å¼")
    only_main_content: bool = Field(default=True, description="ä»…ä¸»è¦å†…å®¹")
    max_concurrent: int = Field(default=5, description="æœ€å¤§å¹¶å‘æ•°")

class HealthResponse(BaseModel):
    """å¥åº·æ£€æŸ¥å“åº”æ¨¡å‹"""
    status: str
    timestamp: str
    version: str
    firecrawl_status: str
    uptime: str

# å…¨å±€å˜é‡
app_start_time = datetime.now()
firecrawl_app = None

@asynccontextmanager
async def lifespan(app: FastAPI):
    """åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    global firecrawl_app
    
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    logger.info("ğŸš€ å¯åŠ¨Firecrawlæ•°æ®é‡‡é›†å™¨APIæœåŠ¡å™¨")
    
    # åˆå§‹åŒ–Firecrawlå®¢æˆ·ç«¯
    api_key = os.getenv("FIRECRAWL_API_KEY")
    if not api_key:
        logger.error("âŒ æœªæ‰¾åˆ°FIRECRAWL_API_KEYç¯å¢ƒå˜é‡")
        raise RuntimeError("FIRECRAWL_API_KEYç¯å¢ƒå˜é‡æœªè®¾ç½®")
    
    try:
        firecrawl_app = FirecrawlApp(api_key=api_key)
        logger.info("âœ… Firecrawlå®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        logger.error(f"âŒ Firecrawlå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}")
        raise
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†
    logger.info("ğŸ›‘ å…³é—­Firecrawlæ•°æ®é‡‡é›†å™¨APIæœåŠ¡å™¨")

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Firecrawlæ•°æ®é‡‡é›†å™¨",
    description="åŸºäºFirecrawl APIçš„æ™ºèƒ½æ•°æ®é‡‡é›†ç³»ç»Ÿ",
    version="1.0.0",
    lifespan=lifespan
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ä¾èµ–æ³¨å…¥
async def get_firecrawl_client():
    """è·å–Firecrawlå®¢æˆ·ç«¯"""
    if firecrawl_app is None:
        raise HTTPException(status_code=503, detail="Firecrawlå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
    return firecrawl_app

# APIè·¯ç”±
@app.get("/", response_model=Dict[str, str])
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "Firecrawlæ•°æ®é‡‡é›†å™¨API",
        "version": "1.0.0",
        "docs": "/docs",
        "health": "/health"
    }

@app.get("/health", response_model=HealthResponse)
async def health_check(client: FirecrawlApp = Depends(get_firecrawl_client)):
    """å¥åº·æ£€æŸ¥"""
    try:
        # æµ‹è¯•Firecrawlè¿æ¥
        test_result = await asyncio.to_thread(
            client.scrape, 
            "https://example.com", 
            {"formats": ["markdown"], "onlyMainContent": True}
        )
        firecrawl_status = "healthy" if test_result else "unhealthy"
    except Exception as e:
        logger.error(f"Firecrawlå¥åº·æ£€æŸ¥å¤±è´¥: {e}")
        firecrawl_status = "unhealthy"
    
    uptime = str(datetime.now() - app_start_time)
    
    return HealthResponse(
        status="healthy",
        timestamp=datetime.now().isoformat(),
        version="1.0.0",
        firecrawl_status=firecrawl_status,
        uptime=uptime
    )

@app.post("/api/v1/crawl/url", response_model=CrawlResponse)
async def crawl_url(
    request: CrawlRequest,
    background_tasks: BackgroundTasks,
    client: FirecrawlApp = Depends(get_firecrawl_client)
):
    """çˆ¬å–å•ä¸ªURL"""
    start_time = datetime.now()
    
    try:
        logger.info(f"å¼€å§‹çˆ¬å–URL: {request.url}")
        
        # æ„å»ºçˆ¬å–å‚æ•°
        crawl_params = {
            "formats": request.formats,
            "onlyMainContent": request.only_main_content,
            "maxDepth": request.max_depth,
            "timeout": request.timeout * 1000  # Firecrawlä½¿ç”¨æ¯«ç§’
        }
        
        # æ‰§è¡Œçˆ¬å–
        result = await asyncio.to_thread(client.scrape, request.url, crawl_params)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        
        logger.info(f"âœ… URLçˆ¬å–æˆåŠŸ: {request.url}, è€—æ—¶: {processing_time:.2f}ç§’")
        
        return CrawlResponse(
            success=True,
            url=request.url,
            content=result,
            timestamp=datetime.now().isoformat(),
            processing_time=processing_time
        )
        
    except Exception as e:
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"âŒ URLçˆ¬å–å¤±è´¥: {request.url}, é”™è¯¯: {e}")
        
        return CrawlResponse(
            success=False,
            url=request.url,
            error=str(e),
            timestamp=datetime.now().isoformat(),
            processing_time=processing_time
        )

@app.post("/api/v1/crawl/batch", response_model=Dict[str, Any])
async def crawl_batch(
    request: BatchCrawlRequest,
    background_tasks: BackgroundTasks,
    client: FirecrawlApp = Depends(get_firecrawl_client)
):
    """æ‰¹é‡çˆ¬å–URL"""
    start_time = datetime.now()
    results = []
    
    # åˆ›å»ºä¿¡å·é‡é™åˆ¶å¹¶å‘æ•°
    semaphore = asyncio.Semaphore(request.max_concurrent)
    
    async def crawl_single_url(url: str) -> Dict[str, Any]:
        """çˆ¬å–å•ä¸ªURLçš„å¼‚æ­¥å‡½æ•°"""
        async with semaphore:
            try:
                crawl_params = {
                    "formats": request.formats,
                    "onlyMainContent": request.only_main_content
                }
                
                result = await asyncio.to_thread(client.scrape, url, crawl_params)
                
                return {
                    "url": url,
                    "success": True,
                    "content": result,
                    "error": None
                }
            except Exception as e:
                return {
                    "url": url,
                    "success": False,
                    "content": None,
                    "error": str(e)
                }
    
    try:
        logger.info(f"å¼€å§‹æ‰¹é‡çˆ¬å– {len(request.urls)} ä¸ªURL")
        
        # å¹¶å‘æ‰§è¡Œçˆ¬å–ä»»åŠ¡
        tasks = [crawl_single_url(url) for url in request.urls]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        processing_time = (datetime.now() - start_time).total_seconds()
        success_count = sum(1 for r in results if r.get("success", False))
        
        logger.info(f"âœ… æ‰¹é‡çˆ¬å–å®Œæˆ: {success_count}/{len(request.urls)} æˆåŠŸ, è€—æ—¶: {processing_time:.2f}ç§’")
        
        return {
            "success": True,
            "total_urls": len(request.urls),
            "successful": success_count,
            "failed": len(request.urls) - success_count,
            "processing_time": processing_time,
            "results": results,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        processing_time = (datetime.now() - start_time).total_seconds()
        logger.error(f"âŒ æ‰¹é‡çˆ¬å–å¤±è´¥: {e}")
        
        return {
            "success": False,
            "error": str(e),
            "processing_time": processing_time,
            "timestamp": datetime.now().isoformat()
        }

@app.get("/api/v1/stats")
async def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    uptime = datetime.now() - app_start_time
    
    return {
        "uptime": str(uptime),
        "start_time": app_start_time.isoformat(),
        "version": "1.0.0",
        "endpoints": [
            "/",
            "/health",
            "/api/v1/crawl/url",
            "/api/v1/crawl/batch",
            "/api/v1/stats"
        ]
    }

# é”™è¯¯å¤„ç†
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return JSONResponse(
        status_code=404,
        content={"error": "æ¥å£ä¸å­˜åœ¨", "path": str(request.url)}
    )

@app.exception_handler(500)
async def internal_error_handler(request, exc):
    logger.error(f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {exc}")
    return JSONResponse(
        status_code=500,
        content={"error": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯", "detail": str(exc)}
    )

if __name__ == "__main__":
    # æ£€æŸ¥ç¯å¢ƒå˜é‡
    if not os.getenv("FIRECRAWL_API_KEY"):
        logger.error("âŒ è¯·è®¾ç½®FIRECRAWL_API_KEYç¯å¢ƒå˜é‡")
        sys.exit(1)
    
    # å¯åŠ¨æœåŠ¡å™¨
    logger.info("ğŸš€ å¯åŠ¨Firecrawlæ•°æ®é‡‡é›†å™¨APIæœåŠ¡å™¨")
    uvicorn.run(
        "enhanced_api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
